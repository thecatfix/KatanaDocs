{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome To The Katana Wiki Katana Diagram Workflow Questions that we need to ask: what is the workflow here This is a general step-by-step workflow that outlines how to use Apache Beam with Google Dataflow to transform securities into pairs, covering the stages of ingestion, cleaning, filtering, warehousing, and the Beam pipeline. The code provides flexible and precise filtering of bonds and application of appropriate models for each universe in downstream processes. Generating Pipelines Source Code Location Docker Images https://console.cloud.google.com/gcr/images/quasar-production/eu/dataflow/templates/flex?project=quasar-production https://console.cloud.google.com/gcr/images/lens-development?project=lens-development Step 1: Ingestion 1. Data Source Identification : Identify the source of your securities data, which could be a database, CSV files, APIs, or real-time streaming data. 2. Data Ingestion : - For batch data, use FileIO to read from CSV or JSON files. - For streaming data, use PubSub or other streaming sources. import apache_beam as beam # Example for reading from a CSV file with beam.Pipeline() as pipeline: securities_data = ( pipeline | 'ReadFromCSV' >> beam.io.ReadFromText('gs://your-bucket/securities.csv', skip_header_lines=1) ) Step 2: Cleaning 3. Data Cleaning : - Remove any leading/trailing whitespace. - Handle missing values (e.g., remove records with null values). - Normalize data (e.g., standardize formats). def clean_data(record): # Implement cleaning logic here return cleaned_record cleaned_data = ( securities_data | 'CleanData' >> beam.Map(clean_data) ) Step 3: Filtering 4. Data Filtering : - Filter out unwanted records based on specific criteria (e.g., only include securities above a certain market cap). def filter_securities(record): # Implement filtering logic here return is_valid_record filtered_data = ( cleaned_data | 'FilterSecurities' >> beam.Filter(filter_securities) ) Step 4: Pairing 5. Pairing Securities : - Transform the filtered data into pairs based on your criteria (e.g., pairing by sector, market cap, etc.). def pair_securities(security_list): # Implement pairing logic here return pairs paired_data = ( filtered_data | 'PairSecurities' >> beam.Map(pair_securities) ) Step 5: Warehousing Data Warehousing : - Write the transformed data to a data warehouse or storage solution (e.g., BigQuery, Cloud Storage). paired_data | 'WriteToBigQuery' >> beam.io.WriteToBigQuery( 'your_project_id:your_dataset.your_table', schema='SCHEMA_AUTODETECT', write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND ) Step 6: Run the Pipeline 7. Run the Dataflow Pipeline : - Execute the pipeline on Google Cloud Dataflow. options = beam.options.pipeline_options.GoogleCloudOptions( project='your_project_id', job_name='securities-pairing', temp_location='gs://your-bucket/temp/', region='your-region' ) pipeline_options = beam.options.pipeline_options.PipelineOptions(flags=[], **options) with beam.Pipeline(options=pipeline_options) as pipeline: # Include all previous steps here Summary This workflow outlines the steps to ingest, clean, filter, pair, and warehouse securities data using Apache Beam and Google Dataflow. You can customize the cleaning, filtering, and pairing logic according to your specific requirements. Make sure to handle exceptions and logging for better monitoring of your pipeline execution.","title":"Welcome To The Katana Wiki"},{"location":"#welcome-to-the-katana-wiki","text":"Katana Diagram Workflow Questions that we need to ask: what is the workflow here This is a general step-by-step workflow that outlines how to use Apache Beam with Google Dataflow to transform securities into pairs, covering the stages of ingestion, cleaning, filtering, warehousing, and the Beam pipeline. The code provides flexible and precise filtering of bonds and application of appropriate models for each universe in downstream processes.","title":"Welcome To The Katana Wiki"},{"location":"#generating-pipelines","text":"Source Code Location Docker Images https://console.cloud.google.com/gcr/images/quasar-production/eu/dataflow/templates/flex?project=quasar-production https://console.cloud.google.com/gcr/images/lens-development?project=lens-development Step 1: Ingestion 1. Data Source Identification : Identify the source of your securities data, which could be a database, CSV files, APIs, or real-time streaming data. 2. Data Ingestion : - For batch data, use FileIO to read from CSV or JSON files. - For streaming data, use PubSub or other streaming sources. import apache_beam as beam # Example for reading from a CSV file with beam.Pipeline() as pipeline: securities_data = ( pipeline | 'ReadFromCSV' >> beam.io.ReadFromText('gs://your-bucket/securities.csv', skip_header_lines=1) ) Step 2: Cleaning 3. Data Cleaning : - Remove any leading/trailing whitespace. - Handle missing values (e.g., remove records with null values). - Normalize data (e.g., standardize formats). def clean_data(record): # Implement cleaning logic here return cleaned_record cleaned_data = ( securities_data | 'CleanData' >> beam.Map(clean_data) ) Step 3: Filtering 4. Data Filtering : - Filter out unwanted records based on specific criteria (e.g., only include securities above a certain market cap). def filter_securities(record): # Implement filtering logic here return is_valid_record filtered_data = ( cleaned_data | 'FilterSecurities' >> beam.Filter(filter_securities) ) Step 4: Pairing 5. Pairing Securities : - Transform the filtered data into pairs based on your criteria (e.g., pairing by sector, market cap, etc.). def pair_securities(security_list): # Implement pairing logic here return pairs paired_data = ( filtered_data | 'PairSecurities' >> beam.Map(pair_securities) ) Step 5: Warehousing Data Warehousing : - Write the transformed data to a data warehouse or storage solution (e.g., BigQuery, Cloud Storage). paired_data | 'WriteToBigQuery' >> beam.io.WriteToBigQuery( 'your_project_id:your_dataset.your_table', schema='SCHEMA_AUTODETECT', write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND ) Step 6: Run the Pipeline 7. Run the Dataflow Pipeline : - Execute the pipeline on Google Cloud Dataflow. options = beam.options.pipeline_options.GoogleCloudOptions( project='your_project_id', job_name='securities-pairing', temp_location='gs://your-bucket/temp/', region='your-region' ) pipeline_options = beam.options.pipeline_options.PipelineOptions(flags=[], **options) with beam.Pipeline(options=pipeline_options) as pipeline: # Include all previous steps here Summary This workflow outlines the steps to ingest, clean, filter, pair, and warehouse securities data using Apache Beam and Google Dataflow. You can customize the cleaning, filtering, and pairing logic according to your specific requirements. Make sure to handle exceptions and logging for better monitoring of your pipeline execution.","title":"Generating Pipelines"},{"location":"1-Ingest-Domain/","text":"The Ingest Domain The Ingest Domain in the Katana Domain Model represents the first stage in the pipeline where raw data (such as bonds and their prices) is collected, processed, and organized into a structured form that can be further analyzed and used in generating trade ideas. The goal of the Ingest process is to ensure that only relevant and high-quality data is passed on for further analysis, making it an essential part of the data preparation process. Key Concepts and Entities in the Ingest Domain: Bond (Entity): - The primary financial instrument considered in the Ingest process. Bonds have several key attributes, such as: - `ISIN`: The unique identifier for each bond. - `Universe`: The financial universe or category to which the bond belongs (e.g., \"USD Investment Grade,\" \"EUR High Yield\"). - Metadata like `IssuerName`, `CountryOfRisk`, `RatingCategory`, `MaturityCategory`, etc. - Bonds are the central data point around which the entire process revolves. BondPrice (Entity): This represents the price of a bond at a specific point in time. Key attributes include: - ISIN : Links the price to the bond it belongs to. - AsOf : The timestamp indicating when the price was recorded. - ZSpread : A measure of risk for the bond compared to risk-free instruments. Bond prices are essential for evaluating trade ideas and are collected for further analysis. BondSpec (Specification): A set of rules or criteria that filters bonds based on certain characteristics before they can be passed on for further processing. For example, BondSpec might require bonds to have a minimum amount of outstanding debt or a maximum number of months to maturity. This ensures that only bonds meeting specific financial standards are included in the downstream processes. BondPriceSpec (Specification): Similarly, this specification filters bond prices based on criteria such as: - The timestamp ( MinAsOf ), ensuring the price data is recent. - The ZSpread , ensuring that only bonds with acceptable risk levels (via their ZSpread values) are included. Universe (Entity): A collection or category of bonds. Universes help group bonds based on specific characteristics, such as geographical location, risk profile, or bond type (e.g., \"USD High Yield\" or \"EUR Investment Grade\"). Ingest Domain Process Breakdown: 1. Data Collection : Bond and BondPrice Data : The Ingest process starts by pulling in raw bond and bond price data from various sources. This data could come from financial data providers, exchanges, or internal systems. The data includes key bond attributes (e.g., ISIN, Issuer, Country of Risk) and bond price records with associated timestamps and ZSpread values. 2. Filtering Bonds (BondSpec) : Once the data is ingested, the BondSpec comes into play. This specification filters bonds to ensure that only those that meet certain criteria are passed on. For example, BondSpec might filter out bonds that have too much time until maturity ( MaxMonthsToMature ) or that have insufficient liquidity ( MinAmountOutstanding ). This stage ensures that only bonds that are tradable and relevant for analysis are included in the process. Bonds that fail to meet the criteria are excluded. This happens in the universes.py file in the generate/components 3. Filtering Bond Prices (BondPriceSpec) : After the bonds have been filtered, the BondPriceSpec applies to the associated bond prices. This specification ensures that the bond price data is up-to-date and within acceptable risk limits. For example, BondPriceSpec might exclude prices that are too old ( MinAsOf ) or prices with a ZSpread value that is too high or too low ( MinZSpread , MaxZSpread ). This ensures that only current, relevant price data is considered for each bond. 4. Assigning Bonds to Universes : Bonds that pass the filtering process are assigned to specific Universes based on their characteristics. A universe represents a category or set of bonds that share similar traits. For example, bonds might be grouped into universes like \"USD Investment Grade\" or \"EUR High Yield.\" These universes help categorize the bonds and enable further downstream analysis within specific financial contexts. 5. Value Object Assignment : The Ingest process also involves assigning various Value Objects to the bonds. These value objects provide additional metadata for the bonds, such as: - **Classification**: The bond's sector (e.g., Corporate, Government). - **Country**: The bond's country of risk. - **Currency**: The currency in which the bond is issued. - **Rating**: The credit rating of the bond. These value objects are non-unique and provide contextual information to help categorize the bonds within the universes. For example, a bond issued by a corporate entity in the USA would have a classification of \"Corporate\" and a country of risk of \"USA.\" 6. Specifications for Universes (UniverseSpec) : The UniverseSpec defines criteria for including bonds in specific universes. For example, a universe might only include bonds with a minimum amount of outstanding debt or bonds issued in certain countries or sectors. Bonds that do not meet the criteria of a particular universe are excluded from that universe. This helps to group bonds effectively and ensures that universes contain only the bonds that meet the desired financial characteristics. 7. Finalizing Ingested Data : Once the bonds have been filtered, their prices validated, and they are assigned to universes, the ingested data is ready for downstream processes. This data, now organized and filtered, can be passed on to the Generate Domain , where it is further analyzed to produce actionable trade ideas. Key Relationships in the Ingest Domain: Bond to BondPrice : - Each bond can have multiple prices over time, and these prices are filtered by BondPriceSpec to ensure only relevant price records are considered. Bond to Universe : - Bonds are assigned to specific universes based on their characteristics and the criteria defined in UniverseSpec . Value Objects to Bonds : - Value objects such as Classification , Country , Currency , and Rating are assigned to bonds to provide additional context for how the bonds should be categorized in the universes. BondSpec and BondPriceSpec : - These specifications play a critical role in filtering the raw bond data to ensure that only bonds meeting the criteria are passed on for further processing. Purpose of the Ingest Domain: Filtering and Structuring Data : - The Ingest Domain serves to organize and filter raw bond data, ensuring that only relevant, high-quality bonds and prices are included in the downstream analysis. Categorization and Contextualization : - By assigning bonds to universes and enriching them with value objects, the Ingest Domain helps create a structured representation of the bond market that can be easily analyzed. Prepares for Trade Idea Generation : - The structured, filtered data is then ready to be passed on to the Generate Domain, where it will be used to create Trade Ideas based on the bonds' price trends, risk levels, and other financial factors. Interpretation: The Ingest Domain is a critical step in the bond trading system, as it ensures that the data fed into later stages is clean, organized, and relevant. By filtering out irrelevant bonds and prices, enriching bonds with value objects, and categorizing them into universes, the Ingest Domain ensures that the subsequent analysis is based on high-quality data. This process lays the foundation for generating accurate and actionable Trade Ideas in the later stages.","title":"The Ingest Domain"},{"location":"1-Ingest-Domain/#the-ingest-domain","text":"The Ingest Domain in the Katana Domain Model represents the first stage in the pipeline where raw data (such as bonds and their prices) is collected, processed, and organized into a structured form that can be further analyzed and used in generating trade ideas. The goal of the Ingest process is to ensure that only relevant and high-quality data is passed on for further analysis, making it an essential part of the data preparation process.","title":"The Ingest Domain"},{"location":"1-Ingest-Domain/#key-concepts-and-entities-in-the-ingest-domain","text":"Bond (Entity): - The primary financial instrument considered in the Ingest process. Bonds have several key attributes, such as: - `ISIN`: The unique identifier for each bond. - `Universe`: The financial universe or category to which the bond belongs (e.g., \"USD Investment Grade,\" \"EUR High Yield\"). - Metadata like `IssuerName`, `CountryOfRisk`, `RatingCategory`, `MaturityCategory`, etc. - Bonds are the central data point around which the entire process revolves. BondPrice (Entity): This represents the price of a bond at a specific point in time. Key attributes include: - ISIN : Links the price to the bond it belongs to. - AsOf : The timestamp indicating when the price was recorded. - ZSpread : A measure of risk for the bond compared to risk-free instruments. Bond prices are essential for evaluating trade ideas and are collected for further analysis. BondSpec (Specification): A set of rules or criteria that filters bonds based on certain characteristics before they can be passed on for further processing. For example, BondSpec might require bonds to have a minimum amount of outstanding debt or a maximum number of months to maturity. This ensures that only bonds meeting specific financial standards are included in the downstream processes. BondPriceSpec (Specification): Similarly, this specification filters bond prices based on criteria such as: - The timestamp ( MinAsOf ), ensuring the price data is recent. - The ZSpread , ensuring that only bonds with acceptable risk levels (via their ZSpread values) are included. Universe (Entity): A collection or category of bonds. Universes help group bonds based on specific characteristics, such as geographical location, risk profile, or bond type (e.g., \"USD High Yield\" or \"EUR Investment Grade\").","title":"Key Concepts and Entities in the Ingest Domain:"},{"location":"1-Ingest-Domain/#ingest-domain-process-breakdown","text":"","title":"Ingest Domain Process Breakdown:"},{"location":"1-Ingest-Domain/#1-data-collection","text":"Bond and BondPrice Data : The Ingest process starts by pulling in raw bond and bond price data from various sources. This data could come from financial data providers, exchanges, or internal systems. The data includes key bond attributes (e.g., ISIN, Issuer, Country of Risk) and bond price records with associated timestamps and ZSpread values.","title":"1. Data Collection:"},{"location":"1-Ingest-Domain/#2-filtering-bonds-bondspec","text":"Once the data is ingested, the BondSpec comes into play. This specification filters bonds to ensure that only those that meet certain criteria are passed on. For example, BondSpec might filter out bonds that have too much time until maturity ( MaxMonthsToMature ) or that have insufficient liquidity ( MinAmountOutstanding ). This stage ensures that only bonds that are tradable and relevant for analysis are included in the process. Bonds that fail to meet the criteria are excluded. This happens in the universes.py file in the generate/components","title":"2. Filtering Bonds (BondSpec):"},{"location":"1-Ingest-Domain/#3-filtering-bond-prices-bondpricespec","text":"After the bonds have been filtered, the BondPriceSpec applies to the associated bond prices. This specification ensures that the bond price data is up-to-date and within acceptable risk limits. For example, BondPriceSpec might exclude prices that are too old ( MinAsOf ) or prices with a ZSpread value that is too high or too low ( MinZSpread , MaxZSpread ). This ensures that only current, relevant price data is considered for each bond.","title":"3. Filtering Bond Prices (BondPriceSpec):"},{"location":"1-Ingest-Domain/#4-assigning-bonds-to-universes","text":"Bonds that pass the filtering process are assigned to specific Universes based on their characteristics. A universe represents a category or set of bonds that share similar traits. For example, bonds might be grouped into universes like \"USD Investment Grade\" or \"EUR High Yield.\" These universes help categorize the bonds and enable further downstream analysis within specific financial contexts.","title":"4. Assigning Bonds to Universes:"},{"location":"1-Ingest-Domain/#5-value-object-assignment","text":"The Ingest process also involves assigning various Value Objects to the bonds. These value objects provide additional metadata for the bonds, such as: - **Classification**: The bond's sector (e.g., Corporate, Government). - **Country**: The bond's country of risk. - **Currency**: The currency in which the bond is issued. - **Rating**: The credit rating of the bond. These value objects are non-unique and provide contextual information to help categorize the bonds within the universes. For example, a bond issued by a corporate entity in the USA would have a classification of \"Corporate\" and a country of risk of \"USA.\"","title":"5. Value Object Assignment:"},{"location":"1-Ingest-Domain/#6-specifications-for-universes-universespec","text":"The UniverseSpec defines criteria for including bonds in specific universes. For example, a universe might only include bonds with a minimum amount of outstanding debt or bonds issued in certain countries or sectors. Bonds that do not meet the criteria of a particular universe are excluded from that universe. This helps to group bonds effectively and ensures that universes contain only the bonds that meet the desired financial characteristics.","title":"6. Specifications for Universes (UniverseSpec):"},{"location":"1-Ingest-Domain/#7-finalizing-ingested-data","text":"Once the bonds have been filtered, their prices validated, and they are assigned to universes, the ingested data is ready for downstream processes. This data, now organized and filtered, can be passed on to the Generate Domain , where it is further analyzed to produce actionable trade ideas.","title":"7. Finalizing Ingested Data:"},{"location":"1-Ingest-Domain/#key-relationships-in-the-ingest-domain","text":"Bond to BondPrice : - Each bond can have multiple prices over time, and these prices are filtered by BondPriceSpec to ensure only relevant price records are considered. Bond to Universe : - Bonds are assigned to specific universes based on their characteristics and the criteria defined in UniverseSpec . Value Objects to Bonds : - Value objects such as Classification , Country , Currency , and Rating are assigned to bonds to provide additional context for how the bonds should be categorized in the universes. BondSpec and BondPriceSpec : - These specifications play a critical role in filtering the raw bond data to ensure that only bonds meeting the criteria are passed on for further processing.","title":"Key Relationships in the Ingest Domain:"},{"location":"1-Ingest-Domain/#purpose-of-the-ingest-domain","text":"Filtering and Structuring Data : - The Ingest Domain serves to organize and filter raw bond data, ensuring that only relevant, high-quality bonds and prices are included in the downstream analysis. Categorization and Contextualization : - By assigning bonds to universes and enriching them with value objects, the Ingest Domain helps create a structured representation of the bond market that can be easily analyzed. Prepares for Trade Idea Generation : - The structured, filtered data is then ready to be passed on to the Generate Domain, where it will be used to create Trade Ideas based on the bonds' price trends, risk levels, and other financial factors.","title":"Purpose of the Ingest Domain:"},{"location":"1-Ingest-Domain/#interpretation","text":"The Ingest Domain is a critical step in the bond trading system, as it ensures that the data fed into later stages is clean, organized, and relevant. By filtering out irrelevant bonds and prices, enriching bonds with value objects, and categorizing them into universes, the Ingest Domain ensures that the subsequent analysis is based on high-quality data. This process lays the foundation for generating accurate and actionable Trade Ideas in the later stages.","title":"Interpretation:"},{"location":"Bloomberg/","text":"","title":"Bloomberg"},{"location":"Bond-Universe/","text":"Purpose Source Code The script's primary purpose is to process bond data from IHS Markit, organize it into different categories (like universes or dropped bonds), and export it to various systems for further analysis or storage. It's a comprehensive tool for managing financial data in a structured and automated way. Setup and Configuration The script starts by setting up the necessary environment. It includes importing libraries and configuring the file path. This is like preparing the workspace with all the tools needed for the job. Data Processing with Apache Beam Classes IngestBondsPerUniverseOptions: A class to handle arguments and parameters for the script. It sets up options like run ID, dates, and target tables for exports. ReadAllBonds: A custom data transformation (PTransform in Beam terms) that reads bond prices and instruments, filters them, and converts them to a Bond object. Export Classes: ExportBonds ExportDroppedBonds ExportUniverse These are responsible for exporting processed bond data to different destinations like BigQuery and Pub/Sub. Pipeline Execution The run function is where the main data processing pipeline is defined. It uses the previously defined transformations to process bonds, group them by certain criteria (like ISIN), filter, and then export them. Different kinds of bonds (e.g., dropped bonds, bonds per universe) are handled separately in the pipeline. Main Function: This is where the script execution starts. It sets up the pipeline options, initializes sources and sinks for data (like ihs_prices_source for reading prices, and dropped_bonds_sink for exporting dropped bonds), and then runs the pipeline. ```","title":"Purpose"},{"location":"Bond-Universe/#purpose","text":"Source Code The script's primary purpose is to process bond data from IHS Markit, organize it into different categories (like universes or dropped bonds), and export it to various systems for further analysis or storage. It's a comprehensive tool for managing financial data in a structured and automated way.","title":"Purpose"},{"location":"Bond-Universe/#setup-and-configuration","text":"The script starts by setting up the necessary environment. It includes importing libraries and configuring the file path. This is like preparing the workspace with all the tools needed for the job.","title":"Setup and Configuration"},{"location":"Bond-Universe/#data-processing-with-apache-beam","text":"Classes IngestBondsPerUniverseOptions: A class to handle arguments and parameters for the script. It sets up options like run ID, dates, and target tables for exports. ReadAllBonds: A custom data transformation (PTransform in Beam terms) that reads bond prices and instruments, filters them, and converts them to a Bond object. Export Classes: ExportBonds ExportDroppedBonds ExportUniverse These are responsible for exporting processed bond data to different destinations like BigQuery and Pub/Sub.","title":"Data Processing with Apache Beam"},{"location":"Bond-Universe/#pipeline-execution","text":"The run function is where the main data processing pipeline is defined. It uses the previously defined transformations to process bonds, group them by certain criteria (like ISIN), filter, and then export them. Different kinds of bonds (e.g., dropped bonds, bonds per universe) are handled separately in the pipeline. Main Function: This is where the script execution starts. It sets up the pipeline options, initializes sources and sinks for data (like ihs_prices_source for reading prices, and dropped_bonds_sink for exporting dropped bonds), and then runs the pipeline. ```","title":"Pipeline Execution"},{"location":"Candidate/","text":"Breakdown of a candidate Based on the usage in the StationarityModel class, a candidate (represented by the IdeaCandidate class) is an object that encapsulates a potential investment idea. Here's a breakdown of what we can infer about a candidate: Structure: It contains two bond objects: bond_buy and bond_sell , representing the bonds to buy and sell in the investment idea. Each bond has properties like country_of_risk , industry_group , rating , and maturity_date . Properties: similarity_score : An optional pre-computed similarity score. bookmark : A boolean flag indicating if the idea is bookmarked. curve_trade : A boolean indicating if it's a curve trade. spread_last_zscore : The last z-score of the spread. spread_mean_reversion : The mean reversion of the spread. Purpose: It represents a potential pair trade or investment opportunity. It contains all the necessary information for the model to evaluate and make predictions about the investment idea. Usage in the Model: The model computes similarities between the buy and sell bonds. It uses the candidate's properties to determine whether to trigger alerts or mark as alternatives. Flexibility: The candidate structure allows for easy comparison between two bonds. It can accommodate various types of trades, including curve trades and bookmarked ideas. Data Encapsulation: It encapsulates all relevant data about an investment idea in a single object. This makes it easier to pass around and analyze potential trades. In summary, a candidate is a comprehensive representation of a potential investment idea, containing all the necessary information for the stationarity model to analyze and make predictions about its viability as a trade opportunity. What are the properties that create IdeaCandidate? Based on the code provided in the stationarity_model.py file, we can infer some of the properties of IdeaCandidate , but we don't have the full class definition. However, from the usage in the _compute_similarity method, we can deduce that IdeaCandidate has at least the following properties: bond_buy : An object representing the bond to buy, which has the following attributes: country_of_risk industry_group rating maturity_date bond_sell : An object representing the bond to sell, with the same attributes as bond_buy . similarity_score : An optional float value representing the pre-computed similarity score. bookmark : A boolean indicating whether the idea is bookmarked. curve_trade : A boolean indicating whether it's a curve trade. Additionally, from the predict method, we can infer a few more properties: spread_last_zscore : An optional float representing the last z-score of the spread. spread_mean_reversion : An optional float representing the mean reversion of the spread. To get a complete and accurate list of all properties that create an IdeaCandidate , we would need to see the actual class definition, which is not present in the provided code snippet. The properties mentioned above are those that are used or referenced within the StationarityModel class, but there could be additional properties not visible in this context. What is a bookmark? In the context of the IdeaCandidate class and the stationarity model, a \"bookmark\" is likely a flag or indicator used to mark specific investment ideas for further attention or quick access. Here's a more detailed explanation: Purpose: A bookmark allows users or algorithms to highlight particular investment ideas that are of special interest, without necessarily changing their analytical properties. Implementation: It's represented as a boolean property ( bookmark ) in the IdeaCandidate class. When True , it indicates that the idea has been bookmarked. Usage in the model: In the predict method of the StationarityModel , we see: if ((similarity_score and similarity_score >= self.similarity_threshold) or candidate.bookmark or candidate.curve_trade): alert = True This suggests that bookmarked ideas are treated with special consideration, potentially triggering alerts even if they don't meet other criteria. Possible applications: Marking ideas for review by human analysts Flagging ideas that meet certain criteria outside of the standard model calculations Allowing users to save ideas they find interesting for later examination Flexibility: The bookmark feature adds a manual or rule-based selection mechanism to complement the algorithmic selection of investment ideas. It's important to note that without access to the full codebase or documentation, this explanation is based on common practices and the context provided in the StationarityModel class. The exact functionality and purpose of bookmarks may vary depending on the specific implementation and business requirements of the system. Detailed breakdown of the predict method in the StationarityModel class: def predict( self, candidate: IdeaCandidate, opts: Dict[str, Any] = None, ) -> ModelResult: Input Parameters: candidate : An IdeaCandidate object representing the investment idea to evaluate. opts : An optional dictionary for additional options (not used in the method body). Similarity Score Calculation: similarity_score = ( candidate.similarity_score if candidate.similarity_score is not None else self._compute_similarity(candidate)) Uses the pre-computed similarity score if available, otherwise calculates it. Initial Variable Setup: pearson_score = 0.99 adf_score = 1.0e-6 alert = False alternative = False Sets default values for Pearson score, ADF score, alert, and alternative flags. Alert Determination: if ((similarity_score and similarity_score >= self.similarity_threshold) or candidate.bookmark or candidate.curve_trade): alert = True Sets alert to True if: The similarity score exists and is above the threshold, or The candidate is bookmarked, or It's a curve trade. Alternative Determination: if ( alert and ( ( candidate.spread_last_zscore is not None and candidate.spread_last_zscore < self.min_zscore_to_alert ) or ( candidate.spread_mean_reversion is not None and candidate.spread_mean_reversion < self.min_zspread_to_alert ) ) ): alert = False alternative = True If an alert was triggered, it checks additional conditions: If the last z-score is below the minimum threshold, or If the mean reversion is below the minimum z-spread threshold. If either condition is true, it changes the idea from an alert to an alternative. Return Result: return ModelResult( alert=alert, alternative=alternative, similarity_score=similarity_score, pearson_score=pearson_score, adf_score=adf_score, ) Returns a ModelResult object with the computed values. Key Points: The method primarily decides whether to trigger an alert or mark the idea as an alternative. It uses pre-computed scores when available, falling back to calculations if necessary. The Pearson and ADF scores are set to constant values, suggesting they might be placeholders for future implementations. The method considers multiple factors: similarity score, bookmarks, curve trades, z-scores, and mean reversion. This method encapsulates the core decision-making logic of the stationarity model, determining how to classify and prioritize investment ideas based on various criteria.","title":"Candidate"},{"location":"Candidate/#breakdown-of-a-candidate","text":"Based on the usage in the StationarityModel class, a candidate (represented by the IdeaCandidate class) is an object that encapsulates a potential investment idea. Here's a breakdown of what we can infer about a candidate: Structure: It contains two bond objects: bond_buy and bond_sell , representing the bonds to buy and sell in the investment idea. Each bond has properties like country_of_risk , industry_group , rating , and maturity_date . Properties: similarity_score : An optional pre-computed similarity score. bookmark : A boolean flag indicating if the idea is bookmarked. curve_trade : A boolean indicating if it's a curve trade. spread_last_zscore : The last z-score of the spread. spread_mean_reversion : The mean reversion of the spread. Purpose: It represents a potential pair trade or investment opportunity. It contains all the necessary information for the model to evaluate and make predictions about the investment idea. Usage in the Model: The model computes similarities between the buy and sell bonds. It uses the candidate's properties to determine whether to trigger alerts or mark as alternatives. Flexibility: The candidate structure allows for easy comparison between two bonds. It can accommodate various types of trades, including curve trades and bookmarked ideas. Data Encapsulation: It encapsulates all relevant data about an investment idea in a single object. This makes it easier to pass around and analyze potential trades. In summary, a candidate is a comprehensive representation of a potential investment idea, containing all the necessary information for the stationarity model to analyze and make predictions about its viability as a trade opportunity.","title":"Breakdown of a candidate"},{"location":"Candidate/#what-are-the-properties-that-create-ideacandidate","text":"Based on the code provided in the stationarity_model.py file, we can infer some of the properties of IdeaCandidate , but we don't have the full class definition. However, from the usage in the _compute_similarity method, we can deduce that IdeaCandidate has at least the following properties: bond_buy : An object representing the bond to buy, which has the following attributes: country_of_risk industry_group rating maturity_date bond_sell : An object representing the bond to sell, with the same attributes as bond_buy . similarity_score : An optional float value representing the pre-computed similarity score. bookmark : A boolean indicating whether the idea is bookmarked. curve_trade : A boolean indicating whether it's a curve trade. Additionally, from the predict method, we can infer a few more properties: spread_last_zscore : An optional float representing the last z-score of the spread. spread_mean_reversion : An optional float representing the mean reversion of the spread. To get a complete and accurate list of all properties that create an IdeaCandidate , we would need to see the actual class definition, which is not present in the provided code snippet. The properties mentioned above are those that are used or referenced within the StationarityModel class, but there could be additional properties not visible in this context.","title":"What are the properties that create IdeaCandidate?"},{"location":"Candidate/#what-is-a-bookmark","text":"In the context of the IdeaCandidate class and the stationarity model, a \"bookmark\" is likely a flag or indicator used to mark specific investment ideas for further attention or quick access. Here's a more detailed explanation: Purpose: A bookmark allows users or algorithms to highlight particular investment ideas that are of special interest, without necessarily changing their analytical properties. Implementation: It's represented as a boolean property ( bookmark ) in the IdeaCandidate class. When True , it indicates that the idea has been bookmarked. Usage in the model: In the predict method of the StationarityModel , we see: if ((similarity_score and similarity_score >= self.similarity_threshold) or candidate.bookmark or candidate.curve_trade): alert = True This suggests that bookmarked ideas are treated with special consideration, potentially triggering alerts even if they don't meet other criteria. Possible applications: Marking ideas for review by human analysts Flagging ideas that meet certain criteria outside of the standard model calculations Allowing users to save ideas they find interesting for later examination Flexibility: The bookmark feature adds a manual or rule-based selection mechanism to complement the algorithmic selection of investment ideas. It's important to note that without access to the full codebase or documentation, this explanation is based on common practices and the context provided in the StationarityModel class. The exact functionality and purpose of bookmarks may vary depending on the specific implementation and business requirements of the system.","title":"What is a bookmark?"},{"location":"Candidate/#detailed-breakdown-of-the-predict-method-in-the-stationaritymodel-class","text":"def predict( self, candidate: IdeaCandidate, opts: Dict[str, Any] = None, ) -> ModelResult: Input Parameters: candidate : An IdeaCandidate object representing the investment idea to evaluate. opts : An optional dictionary for additional options (not used in the method body). Similarity Score Calculation: similarity_score = ( candidate.similarity_score if candidate.similarity_score is not None else self._compute_similarity(candidate)) Uses the pre-computed similarity score if available, otherwise calculates it. Initial Variable Setup: pearson_score = 0.99 adf_score = 1.0e-6 alert = False alternative = False Sets default values for Pearson score, ADF score, alert, and alternative flags. Alert Determination: if ((similarity_score and similarity_score >= self.similarity_threshold) or candidate.bookmark or candidate.curve_trade): alert = True Sets alert to True if: The similarity score exists and is above the threshold, or The candidate is bookmarked, or It's a curve trade. Alternative Determination: if ( alert and ( ( candidate.spread_last_zscore is not None and candidate.spread_last_zscore < self.min_zscore_to_alert ) or ( candidate.spread_mean_reversion is not None and candidate.spread_mean_reversion < self.min_zspread_to_alert ) ) ): alert = False alternative = True If an alert was triggered, it checks additional conditions: If the last z-score is below the minimum threshold, or If the mean reversion is below the minimum z-spread threshold. If either condition is true, it changes the idea from an alert to an alternative. Return Result: return ModelResult( alert=alert, alternative=alternative, similarity_score=similarity_score, pearson_score=pearson_score, adf_score=adf_score, ) Returns a ModelResult object with the computed values. Key Points: The method primarily decides whether to trigger an alert or mark the idea as an alternative. It uses pre-computed scores when available, falling back to calculations if necessary. The Pearson and ADF scores are set to constant values, suggesting they might be placeholders for future implementations. The method considers multiple factors: similarity score, bookmarks, curve trades, z-scores, and mean reversion. This method encapsulates the core decision-making logic of the stationarity model, determining how to classify and prioritize investment ideas based on various criteria.","title":"Detailed breakdown of the predict method in the StationarityModel class:"},{"location":"Classifications/","text":"Classification Filtering in Bonds The Classification Filtering implemented in the method has_correct_classification ensures that bonds are filtered based on their classification attributes, which are usually defined in terms of a super type and a sub type . These classifications represent how a bond is categorized within a financial domain, such as its asset class, industry sector, or security type. Breakdown of the has_correct_classification Filtering Process 1. Super Type and Sub Type Every bond can be classified by a super type and a sub type , which represent broad and specific categories, respectively. For example: Super Type could be something general like \"Corporate Bond\" or \"Government Bond.\" Sub Type could further narrow down the category, such as \"Investment Grade Corporate Bond\" or \"Municipal Government Bond.\" 2. Universe-Specific Preferences Each Universe defines a set of preferred classifications (both super type and sub type). These preferences indicate what types of bonds are allowed to pass through the filter and be included in that universe. For example, a universe may specify that it only includes \"Government Bonds\" (super type) with \"Sovereign\" or \"Agency\" classifications (sub type). Any bonds that don't match this classification will be filtered out. 3. Filtering Logic The has_correct_classification method checks the bond's classification against the universe's specified preferences: Super Type Matching : First, it verifies if the bond's super type matches one of the preferred super types for that universe. Sub Type Matching : If the super type matches, it then checks if the bond's sub type is also in the list of preferred sub types. If both the super type and sub type match the universe's specifications, the bond passes this filter and is included for further processing. If not, the bond is excluded. 4. Inclusion and Exclusion Lists The filtering mechanism might also have inclusion and exclusion lists . This means that: Bonds explicitly listed in an inclusion list will pass through, regardless of their classification. Bonds in an exclusion list will be filtered out, even if their classification would normally pass the filter. Example Scenario Imagine the following universe settings: Super Type : Corporate Bond Sub Type : Investment Grade, High Yield And the bond classifications are: Bond A : Corporate Bond (Super Type), Investment Grade (Sub Type) -- Passes the filter . Bond B : Corporate Bond (Super Type), High Yield (Sub Type) -- Passes the filter . Bond C : Government Bond (Super Type), Sovereign (Sub Type) -- Fails the filter because the super type doesn't match the universe's settings. Bond D : Corporate Bond (Super Type), Speculative (Sub Type) -- Fails the filter because the sub type is not part of the preferred classifications. Purpose of the Classification Filter The classification filter ensures that only bonds which belong to specific financial categories, as defined by the universe, are included in the analysis or trade idea generation process. This allows financial analysts or automated systems to focus only on bonds that fit their investment strategies or risk profiles, which are often defined by classification. Location of Logic for Classification Filtering Classification filtering logic in bond.py Key Elements in the Classification Filtering Classifications in the Universe The universe defines a list of classifications (both super types and sub types) that it prefers. These are specified within the universe.classifications list. Classification Super Type and Sub Type Bonds are categorized by both a super type (e.g., \"Corporate\", \"Government\") and a sub type (e.g., \"Domestic\", \"Eurobond\"). The filtering logic first checks the bond's super type against the universe's preferences, and then it checks the sub type to ensure the bond matches. Logic Inside has_correct_classification The function loops over the universe's preferred classifications. If the bond's super type matches a preferred super type, the bond passes the filter. If the bond's sub type matches a preferred sub type, the bond also passes the filter. If both a super type and a sub type are provided in the form of a tuple (i.e., both are expected to match), the bond must match both to pass the filter. Example Filtering Scenario If a universe prefers the classification Corporate Bonds (super type) with a sub type of Domestic , only bonds that are classified as Corporate Bonds with the Domestic sub type will pass this filter. If the universe doesn't specify any classifications, all bonds will pass this part of the filter. Code Reference This filtering logic is directly implemented in the has_correct_classification function within the BondsUniverseFilter class, located in your file. ```","title":"Classification Filtering in Bonds"},{"location":"Classifications/#classification-filtering-in-bonds","text":"The Classification Filtering implemented in the method has_correct_classification ensures that bonds are filtered based on their classification attributes, which are usually defined in terms of a super type and a sub type . These classifications represent how a bond is categorized within a financial domain, such as its asset class, industry sector, or security type.","title":"Classification Filtering in Bonds"},{"location":"Classifications/#breakdown-of-the-has_correct_classification-filtering-process","text":"","title":"Breakdown of the has_correct_classification Filtering Process"},{"location":"Classifications/#1-super-type-and-sub-type","text":"Every bond can be classified by a super type and a sub type , which represent broad and specific categories, respectively. For example: Super Type could be something general like \"Corporate Bond\" or \"Government Bond.\" Sub Type could further narrow down the category, such as \"Investment Grade Corporate Bond\" or \"Municipal Government Bond.\"","title":"1. Super Type and Sub Type"},{"location":"Classifications/#2-universe-specific-preferences","text":"Each Universe defines a set of preferred classifications (both super type and sub type). These preferences indicate what types of bonds are allowed to pass through the filter and be included in that universe. For example, a universe may specify that it only includes \"Government Bonds\" (super type) with \"Sovereign\" or \"Agency\" classifications (sub type). Any bonds that don't match this classification will be filtered out.","title":"2. Universe-Specific Preferences"},{"location":"Classifications/#3-filtering-logic","text":"The has_correct_classification method checks the bond's classification against the universe's specified preferences: Super Type Matching : First, it verifies if the bond's super type matches one of the preferred super types for that universe. Sub Type Matching : If the super type matches, it then checks if the bond's sub type is also in the list of preferred sub types. If both the super type and sub type match the universe's specifications, the bond passes this filter and is included for further processing. If not, the bond is excluded.","title":"3. Filtering Logic"},{"location":"Classifications/#4-inclusion-and-exclusion-lists","text":"The filtering mechanism might also have inclusion and exclusion lists . This means that: Bonds explicitly listed in an inclusion list will pass through, regardless of their classification. Bonds in an exclusion list will be filtered out, even if their classification would normally pass the filter.","title":"4. Inclusion and Exclusion Lists"},{"location":"Classifications/#example-scenario","text":"Imagine the following universe settings: Super Type : Corporate Bond Sub Type : Investment Grade, High Yield And the bond classifications are: Bond A : Corporate Bond (Super Type), Investment Grade (Sub Type) -- Passes the filter . Bond B : Corporate Bond (Super Type), High Yield (Sub Type) -- Passes the filter . Bond C : Government Bond (Super Type), Sovereign (Sub Type) -- Fails the filter because the super type doesn't match the universe's settings. Bond D : Corporate Bond (Super Type), Speculative (Sub Type) -- Fails the filter because the sub type is not part of the preferred classifications.","title":"Example Scenario"},{"location":"Classifications/#purpose-of-the-classification-filter","text":"The classification filter ensures that only bonds which belong to specific financial categories, as defined by the universe, are included in the analysis or trade idea generation process. This allows financial analysts or automated systems to focus only on bonds that fit their investment strategies or risk profiles, which are often defined by classification.","title":"Purpose of the Classification Filter"},{"location":"Classifications/#location-of-logic-for-classification-filtering","text":"Classification filtering logic in bond.py","title":"Location of Logic for Classification Filtering"},{"location":"Classifications/#key-elements-in-the-classification-filtering","text":"Classifications in the Universe The universe defines a list of classifications (both super types and sub types) that it prefers. These are specified within the universe.classifications list. Classification Super Type and Sub Type Bonds are categorized by both a super type (e.g., \"Corporate\", \"Government\") and a sub type (e.g., \"Domestic\", \"Eurobond\"). The filtering logic first checks the bond's super type against the universe's preferences, and then it checks the sub type to ensure the bond matches. Logic Inside has_correct_classification The function loops over the universe's preferred classifications. If the bond's super type matches a preferred super type, the bond passes the filter. If the bond's sub type matches a preferred sub type, the bond also passes the filter. If both a super type and a sub type are provided in the form of a tuple (i.e., both are expected to match), the bond must match both to pass the filter.","title":"Key Elements in the Classification Filtering"},{"location":"Classifications/#example-filtering-scenario","text":"If a universe prefers the classification Corporate Bonds (super type) with a sub type of Domestic , only bonds that are classified as Corporate Bonds with the Domestic sub type will pass this filter. If the universe doesn't specify any classifications, all bonds will pass this part of the filter.","title":"Example Filtering Scenario"},{"location":"Classifications/#code-reference","text":"This filtering logic is directly implemented in the has_correct_classification function within the BondsUniverseFilter class, located in your file. ```","title":"Code Reference"},{"location":"Data-Source-Specifications/","text":"","title":"Data Source Specifications"},{"location":"Domain-Model/","text":"Combined Domain Model Diagram Ingest Generate Discover Explaining Domain Model Entity Data Holder: An entity holds data within your domain model. Unique Identification: Each entity is uniquely identifiable, distinguishing it from other entities. Lifecycle and Persistence: Entities have a lifecycle (creation, modification, deletion) and thus need to be persisted in a database or another storage system. Value Object Data Holder: Similar to entities, value objects hold data. Non-unique: Unlike entities, value objects don't need to be unique within the domain. On-demand Creation: They can be created as needed and are more transient. Replication and Re-use: Value objects can be replicated and reused across the system. No Lifecycle: They don't have a lifecycle and are typically not persisted, though they can be for convenience. Aggregate Collection of Entities and Value Objects: An aggregate groups related entities and value objects. Internal Utility: The elements within an aggregate are not typically useful outside of it. Root Element: There's a root element in each aggregate that acts as an anchor point and public interface for the internal elements. Repository Entity Storage and Retrieval: Repositories handle the storage and retrieval of entities, which could be aggregate roots. Abstraction Over Persistence: They abstract away the underlying persistence mechanism, like databases. Stream Entity Flow: A stream is a conduit for a specific type of entity, facilitating the flow of these entities within the system. Receive and Send Entities: Streams can be used to both receive and send entities. Service Functionality Collection: A service in your domain model represents a collection of related functionalities. Stateless: Services typically don't have their own persisted state. Index The description for \"Index\" is missing in your glossary. Usually, an index refers to a data structure that improves the speed of data retrieval operations. Core Domain Central Functionalities: The core domain likely includes the central, most crucial functionalities of your system. It's referenced as a separate document Core . Sub Domains These are specific areas within your domain model, each focusing on different aspects of the system. They are also referenced as separate documents, indicating detailed descriptions elsewhere: Ingest Generate Discover Authenticate & Collaborate Notify Your domain model seems well-structured, dividing the system into clear, manageable parts, each with a specific role. This structure aids in both understanding and maintaining the system. Core Your Core domain model, represented using a mermaid class diagram, clearly outlines the relationships between the primary entities in your system: Bond , BondPrice , Universe , and TradeIdea . Here's a description of the classes and their relationships: Classes and Their Fields Bond ISIN (International Securities Identification Number): A unique identifier for each bond. BondPrice ISIN : The identifier of the bond, linking it to the Bond class. AsOf : A timestamp indicating when the price was recorded. ZSpread : The Z-Spread value of the bond. Universe Name : The name of a universe. In financial contexts, a universe often refers to a collection or set of bonds. TradeIdea ID : A unique identifier for the trade idea, derived from the concatenation of the BondBuyISIN and BondSellISIN . Relationships BondPrice --> Bond: Each BondPrice is associated with a Bond . The ISIN field in BondPrice links to the corresponding Bond . Universe o-- Bond: This represents a one-to-many relationship where a Universe can contain multiple Bonds . Bond *-- TradeIdea (buy and sell): A TradeIdea is associated with two Bonds , one to buy and one to sell. This is a many-to-one relationship where multiple trade ideas can involve the same bond. BondPrice *-- TradeIdea (buy and sell): Similar to the Bond relationship, a TradeIdea is also associated with the BondPrice for both the buying and selling bonds. Universe o-- TradeIdea: A Universe can contain multiple TradeIdeas . This relationship indicates that trade ideas are categorized or grouped under different universes. This class diagram effectively represents the core relationships in your financial trading system, particularly focusing on how trade ideas are formulated based on bonds, their prices, and the universes they belong to. ```mermaid classDiagram class Bond { string ISIN } class BondPrice { string ISIN time AsOf float ZSpread } class Universe { string Name } class TradeIdea { string ID %% BondBuyISIN+BondSellISIN } BondPrice --> Bond Universe o-- Bond Bond *-- TradeIdea : buy BondPrice *-- TradeIdea : buy Bond *-- TradeIdea : sell BondPrice *-- TradeIdea : sell Universe o-- TradeIdea ``` Ingest The Ingest section of your domain model, depicted using a mermaid class diagram, represents the structure and relationships involved in the ingestion process of your financial trading system. This diagram showcases several classes, primarily focusing on the characteristics of bonds and their categorization within universes. Let's delve into the details: Classes and Their Attributes Bond An entity with fields like ISIN (a unique identifier) and Universe (the universe to which the bond belongs). Universe An entity identified by Name . Value Objects Include Classification , Country , Currency , Flag , IssueType , Rating , Ticker , IndustrySectorLevel1 , IndustrySectorLevel4 , and PaymentCategory . These are data holders without unique identifiers within the domain. UniverseSpec A specification with a field MinAmountOutstanding , indicating the minimum amount outstanding for a bond to be included in a universe. Relationships Value Objects *-- UniverseSpec: Value objects like Classification , Country , etc., are included or excluded in UniverseSpec . This indicates that UniverseSpec criteria can specify the inclusion or exclusion of bonds based on these characteristics. UniverseSpec \"1\" ..|> \"1\" Universe: A one-to-one relationship where UniverseSpec is a part of Universe . UniverseSpec \"1\" ..|> \"*\" Bond: A one-to-many relationship where UniverseSpec can apply to multiple Bonds . This relationship suggests that UniverseSpec defines the criteria for including bonds in a universe. Bond \"\" o-- \"\" Universe: A many-to-many relationship indicating that bonds can belong to multiple universes and vice versa. Interpretation This model primarily focuses on the criteria and specifications for including bonds in different universes. It highlights how various attributes of bonds, such as their classifications, ratings, and sectors, play a role in categorizing them. The use of value objects like Country , Currency , and Rating emphasizes the importance of these characteristics in the bond universe categorization process. Overall, the Ingest domain model provides a structured way to categorize bonds based on multiple criteria, essential for organizing and analyzing financial securities in a trading system. Generate The Generate section of your domain model, illustrated using a mermaid class diagram, portrays the process and entities involved in generating trade ideas in your financial system. This diagram highlights the entities, value objects, specifications, and their interconnections. Let's examine the key components: Entities and Value Objects Bond An entity characterized by ISIN and Universe . BondSpec A specification defining criteria like MaxMonthsToMature and MinAmountOutstanding for bonds. BondPrice An entity representing the price of a bond at a specific time, identified by ISIN , AsOf date, and ZSpread . BondPriceSpec A specification with criteria for bond prices, such as MinAsOf , MinZSpread , and MaxZSpread . BondWithPrices A value object representing a bond with its associated prices. BondWithPricesSpec A specification for BondWithPrices , including criteria like MaxEWMScore , MaxDODScore , etc. Universe An entity identified by Name , representing a collection of bonds. Bookmark An entity representing a bookmarked trade idea, identified by TradeIdeaID . BondPair A value object indicating a pair of bonds, possibly bookmarked. TradeIdeaCandidate An entity with attributes like ID , IsBookmarked , various spread values, and scores. TradeIdeaCandidateSpec A specification for trade idea candidates, including criteria like MinSpreadMeanReversion , MinPearsonScore , etc. Model An entity representing a predictive model, identified by ID . TradeIdeaSpec A specification for trade ideas, including criteria like MinSimilarityScore , MinPearsonScore , etc. TradeIdea An entity representing a potential trade idea, identified by a concatenated ID from two ISINs. Relationships Bond -- BondWithPrices; BondPrice -- BondWithPrices: Bonds and their prices are associated with BondWithPrices . BondWithPrices o-- BondPair: Bond pairs are formed from bonds with prices. Bookmark ..> BondPair: Bookmarks can be associated with bond pairs. BondPair ..|> TradeIdeaCandidate; TradeIdeaCandidate ..|> TradeIdea: Bond pairs are used to generate trade idea candidates, which can become trade ideas. Specs to Entities/Value Objects: Specifications ( BondSpec , BondPriceSpec , etc.) are linked to their corresponding entities or value objects, defining criteria or rules for them. Universe o-- Bond; Universe o-- TradeIdea: Bonds and trade ideas are associated with universes. Model ..> TradeIdeaSpec; TradeIdeaSpec --> TradeIdeaCandidate: Models influence trade idea specifications, which in turn apply to trade idea candidates. Interpretation This model emphasizes the generation of trade ideas from bond data. It showcases how various specifications and criteria filter and refine bonds, their prices, and pairs to form viable trade idea candidates. The presence of value objects like BondWithPrices and BondPair indicates the aggregation of data from different entities to form meaningful combinations. The use of bookmarks suggests that certain bond pairs or trade ideas can be flagged for special attention. Finally, the transition from TradeIdeaCandidate to TradeIdea signifies the final step in the generation process, where candidates are evaluated against specific models and criteria to become actionable trade ideas. Discover The Discover section of your domain model, illustrated using a mermaid class diagram, details the structure and interactions for discovering trade ideas within your financial system. This comprehensive model includes various entities, value objects, services, and their relationships. Let's delve into its components: Entities and Value Objects Bond An entity with attributes like ISIN , Name , IssueDate , IssuerName , CountryOfRisk , etc. BondPrice An entity representing a bond's price at a specific time, identified by ISIN , AsOf date, and ZSpread . BondPricePair A value object representing a pair of bond prices. BondPricePairWithStats A value object that includes statistics like Diff , Mean , StdDev , and an IsIdea flag. Universe An entity representing a collection of bonds, identified by Name . TradeIdea An entity representing a potential trade idea, identified by concatenated ISINs of BondBuy and BondSell . Filters (TagFilter, MatchFilter, LikeFilter, RangeFilter, ExcludeFilter) Value objects representing different types of filters used in search criteria. Page A value object for pagination details such as Number , Size , and Total . OrderDirection (Enum) and Order OrderDirection is an enumeration for sorting direction, and Order is a value object specifying the field and direction for ordering. SearchCriteria A value object defining the search criteria, including universe, filters, order, and pagination. Facets (TagFacet, RangeFacet, MatchFacet) Value objects representing facets for search results. SearchResult A value object encapsulating the results of a search, including items, facets, order, pagination, and total item count. TradeIdeaService (Service) A service for executing searches based on SearchCriteria and returning SearchResult . Relationships BondPrice -- Bond; BondPricePair -- BondPrice: Bonds are associated with their prices, and bond price pairs are linked to individual bond prices. Bond -- Universe; TradeIdea -- Universe; SearchResult *-- Universe: Bonds, trade ideas, and search results are associated with universes. TradeIdea *-- Bond: Trade ideas are linked to buy and sell bonds. SearchCriteria o-- Filters; SearchResult o-- Facets: Search criteria include various filters, and search results contain facets. Order -- SearchCriteria; Page -- SearchCriteria; Order -- SearchResult; Page -- SearchResult: Order and page details are used in both search criteria and results. SearchCriteria ..> TradeIdeaService; TradeIdeaService ..|> SearchResult: Search criteria are used by the TradeIdeaService to generate search results. Interpretation This diagram illustrates the discovery process within the trading system, focusing on how trade ideas are identified, filtered, and presented. It highlights the importance of flexible search criteria, including various filters and sorting options, facilitating targeted searches within the bond universe. The presence of statistical value objects like BondPricePairWithStats suggests an analytical approach to identifying potential trade ideas. The TradeIdeaService plays a central role, acting as the interface for processing search queries and returning structured results. The model also emphasizes the importance of pagination and sorting in managing and presenting search results, ensuring a user-friendly discovery experience. Overall, the Discover section of your domain model portrays a robust system for exploring and identifying trade opportunities in the financial market. Authenticate & Collaborate The Authenticate & Collaborate section of your domain model illustrates the structure and interactions of entities and services involved in user authentication and collaboration in the context of a financial trading system. It includes entities like Team , AuthUser , User , bookmarks, comments, and channels, along with streams for bookmarks and comments. Let's break down the main components and their relationships: Entities and Aggregates Team Represents a team within a company, with attributes like Company and Name . AuthUser Represents an authenticated user, identified by UID and Email . User Represents a user within the system, linked to a company, team, and authenticated user ID ( UID ). EnrichedUser An aggregate that enriches an AuthUser with more detailed information from User . Bookmark Represents a bookmarked trade idea, associated with a user, team, and specific trade idea ID. BookmarkChannel An entity that allows users to publish and subscribe to bookmarks. It is associated with a specific team. Comment Represents a user's comment, linked to a team and user. CommentChannel An entity for publishing and subscribing to comments, associated with a team. Streams BookmarkStream and CommentStream Streams for bookmarks and comments, respectively, facilitating real-time communication and updates. Relationships AuthUser -- EnrichedUser; User -- EnrichedUser: Authenticated users are enriched with additional information to form EnrichedUser . User, Bookmark, Comment --> Team: Users, bookmarks, and comments are associated with a specific team. Bookmark, Comment --> User: Bookmarks and comments are linked to individual users. Bookmark o-- BookmarkStream; Comment o-- CommentStream: Bookmarks and comments are part of their respective streams. BookmarkChannel, CommentChannel --> Team: Channels for bookmarks and comments are tied to specific teams. BookmarkChannel, CommentChannel ..|> BookmarkStream, CommentStream: Channels publish to and subscribe from their respective streams. User ..|> BookmarkChannel, CommentChannel: Users can publish to and subscribe from bookmark and comment channels. Interpretation The model emphasizes the collaborative aspect of the trading system, where users within a company's teams can interact, share insights, and collaborate on trade ideas. It highlights the importance of real-time communication through bookmark and comment channels, supported by streams that ensure continuous updates and interactions. The inclusion of AuthUser and EnrichedUser suggests a robust authentication system that securely manages user identities while enriching them with relevant team and company information. This ensures that users operate within the context of their organizational structures, maintaining data security and compliance. The model also demonstrates the use of bookmarks and comments as key collaborative tools, allowing users to highlight important trade ideas and engage in discussions. This fosters a community-driven approach to decision-making and idea generation in the financial trading environment. Overall, the Authenticate & Collaborate section of your domain model portrays a sophisticated and secure platform for user authentication and collaboration, enhancing the user experience in a financial trading system. Notify The Notify section of your domain model outlines the notification system within your application, primarily focusing on how users receive notifications. Here's a breakdown of the components and their relationships: Entities and Value Objects User Represents a user in the system, uniquely identified by UID . Notification Represents a notification entity containing an ID , Text (message of the notification), and Link (possibly pointing to related content or action). NotificationChannel A value object that represents a channel through which users can subscribe to receive notifications. Stream NotificationStream A stream that holds all the notifications, serving as a central pipeline through which notifications flow. Relationships Notification o-- NotificationStream: Notifications are part of the NotificationStream, indicating that all notifications flow through this centralized stream. NotificationChannel ..> NotificationStream: The NotificationChannel subscribes to the NotificationStream. This relationship implies that the channel receives data from the stream, likely to forward it to subscribed users. User ..> NotificationChannel: Users subscribe to the NotificationChannel to receive notifications. This relationship indicates that notifications are pushed to users through these channels. Interpretation The model illustrates a straightforward notification system. When a notification is created, it enters the NotificationStream. NotificationChannels are subscribed to this stream, and they relay notifications to users who have subscribed to these channels. The use of a stream for notifications suggests a real-time or near-real-time system where notifications are continuously pushed through the stream and distributed to users. This approach is effective for applications requiring timely updates, such as messaging apps, social media platforms, or systems where prompt user response is critical. The simplicity of the model focuses on the flow of notifications from their creation to the end user. It abstracts away the complexities of how notifications are generated or the criteria for pushing specific notifications to particular users. This high-level view is beneficial for understanding the overall architecture without getting bogged down in implementation details. In summary, the Notify section of your domain model provides a clear picture of the notification delivery mechanism in your application, emphasizing real-time communication and user engagement.","title":"Combined Domain Model Diagram"},{"location":"Domain-Model/#combined-domain-model-diagram","text":"","title":"Combined Domain Model Diagram"},{"location":"Domain-Model/#ingest","text":"","title":"Ingest"},{"location":"Domain-Model/#generate","text":"","title":"Generate"},{"location":"Domain-Model/#discover","text":"Explaining Domain Model","title":"Discover"},{"location":"Domain-Model/#entity","text":"Data Holder: An entity holds data within your domain model. Unique Identification: Each entity is uniquely identifiable, distinguishing it from other entities. Lifecycle and Persistence: Entities have a lifecycle (creation, modification, deletion) and thus need to be persisted in a database or another storage system.","title":"Entity"},{"location":"Domain-Model/#value-object","text":"Data Holder: Similar to entities, value objects hold data. Non-unique: Unlike entities, value objects don't need to be unique within the domain. On-demand Creation: They can be created as needed and are more transient. Replication and Re-use: Value objects can be replicated and reused across the system. No Lifecycle: They don't have a lifecycle and are typically not persisted, though they can be for convenience.","title":"Value Object"},{"location":"Domain-Model/#aggregate","text":"Collection of Entities and Value Objects: An aggregate groups related entities and value objects. Internal Utility: The elements within an aggregate are not typically useful outside of it. Root Element: There's a root element in each aggregate that acts as an anchor point and public interface for the internal elements.","title":"Aggregate"},{"location":"Domain-Model/#repository","text":"Entity Storage and Retrieval: Repositories handle the storage and retrieval of entities, which could be aggregate roots. Abstraction Over Persistence: They abstract away the underlying persistence mechanism, like databases.","title":"Repository"},{"location":"Domain-Model/#stream","text":"Entity Flow: A stream is a conduit for a specific type of entity, facilitating the flow of these entities within the system. Receive and Send Entities: Streams can be used to both receive and send entities.","title":"Stream"},{"location":"Domain-Model/#service","text":"Functionality Collection: A service in your domain model represents a collection of related functionalities. Stateless: Services typically don't have their own persisted state.","title":"Service"},{"location":"Domain-Model/#index","text":"The description for \"Index\" is missing in your glossary. Usually, an index refers to a data structure that improves the speed of data retrieval operations.","title":"Index"},{"location":"Domain-Model/#core-domain","text":"Central Functionalities: The core domain likely includes the central, most crucial functionalities of your system. It's referenced as a separate document Core .","title":"Core Domain"},{"location":"Domain-Model/#sub-domains","text":"These are specific areas within your domain model, each focusing on different aspects of the system. They are also referenced as separate documents, indicating detailed descriptions elsewhere: Ingest Generate Discover Authenticate & Collaborate Notify Your domain model seems well-structured, dividing the system into clear, manageable parts, each with a specific role. This structure aids in both understanding and maintaining the system.","title":"Sub Domains"},{"location":"Domain-Model/#core","text":"Your Core domain model, represented using a mermaid class diagram, clearly outlines the relationships between the primary entities in your system: Bond , BondPrice , Universe , and TradeIdea . Here's a description of the classes and their relationships:","title":"Core"},{"location":"Domain-Model/#classes-and-their-fields","text":"Bond ISIN (International Securities Identification Number): A unique identifier for each bond. BondPrice ISIN : The identifier of the bond, linking it to the Bond class. AsOf : A timestamp indicating when the price was recorded. ZSpread : The Z-Spread value of the bond. Universe Name : The name of a universe. In financial contexts, a universe often refers to a collection or set of bonds. TradeIdea ID : A unique identifier for the trade idea, derived from the concatenation of the BondBuyISIN and BondSellISIN .","title":"Classes and Their Fields"},{"location":"Domain-Model/#relationships","text":"BondPrice --> Bond: Each BondPrice is associated with a Bond . The ISIN field in BondPrice links to the corresponding Bond . Universe o-- Bond: This represents a one-to-many relationship where a Universe can contain multiple Bonds . Bond *-- TradeIdea (buy and sell): A TradeIdea is associated with two Bonds , one to buy and one to sell. This is a many-to-one relationship where multiple trade ideas can involve the same bond. BondPrice *-- TradeIdea (buy and sell): Similar to the Bond relationship, a TradeIdea is also associated with the BondPrice for both the buying and selling bonds. Universe o-- TradeIdea: A Universe can contain multiple TradeIdeas . This relationship indicates that trade ideas are categorized or grouped under different universes. This class diagram effectively represents the core relationships in your financial trading system, particularly focusing on how trade ideas are formulated based on bonds, their prices, and the universes they belong to. ```mermaid classDiagram class Bond { string ISIN } class BondPrice { string ISIN time AsOf float ZSpread } class Universe { string Name } class TradeIdea { string ID %% BondBuyISIN+BondSellISIN } BondPrice --> Bond Universe o-- Bond Bond *-- TradeIdea : buy BondPrice *-- TradeIdea : buy Bond *-- TradeIdea : sell BondPrice *-- TradeIdea : sell Universe o-- TradeIdea ```","title":"Relationships"},{"location":"Domain-Model/#ingest_1","text":"The Ingest section of your domain model, depicted using a mermaid class diagram, represents the structure and relationships involved in the ingestion process of your financial trading system. This diagram showcases several classes, primarily focusing on the characteristics of bonds and their categorization within universes. Let's delve into the details:","title":"Ingest"},{"location":"Domain-Model/#classes-and-their-attributes","text":"Bond An entity with fields like ISIN (a unique identifier) and Universe (the universe to which the bond belongs). Universe An entity identified by Name . Value Objects Include Classification , Country , Currency , Flag , IssueType , Rating , Ticker , IndustrySectorLevel1 , IndustrySectorLevel4 , and PaymentCategory . These are data holders without unique identifiers within the domain. UniverseSpec A specification with a field MinAmountOutstanding , indicating the minimum amount outstanding for a bond to be included in a universe.","title":"Classes and Their Attributes"},{"location":"Domain-Model/#relationships_1","text":"Value Objects *-- UniverseSpec: Value objects like Classification , Country , etc., are included or excluded in UniverseSpec . This indicates that UniverseSpec criteria can specify the inclusion or exclusion of bonds based on these characteristics. UniverseSpec \"1\" ..|> \"1\" Universe: A one-to-one relationship where UniverseSpec is a part of Universe . UniverseSpec \"1\" ..|> \"*\" Bond: A one-to-many relationship where UniverseSpec can apply to multiple Bonds . This relationship suggests that UniverseSpec defines the criteria for including bonds in a universe. Bond \"\" o-- \"\" Universe: A many-to-many relationship indicating that bonds can belong to multiple universes and vice versa.","title":"Relationships"},{"location":"Domain-Model/#interpretation","text":"This model primarily focuses on the criteria and specifications for including bonds in different universes. It highlights how various attributes of bonds, such as their classifications, ratings, and sectors, play a role in categorizing them. The use of value objects like Country , Currency , and Rating emphasizes the importance of these characteristics in the bond universe categorization process. Overall, the Ingest domain model provides a structured way to categorize bonds based on multiple criteria, essential for organizing and analyzing financial securities in a trading system.","title":"Interpretation"},{"location":"Domain-Model/#generate_1","text":"The Generate section of your domain model, illustrated using a mermaid class diagram, portrays the process and entities involved in generating trade ideas in your financial system. This diagram highlights the entities, value objects, specifications, and their interconnections. Let's examine the key components:","title":"Generate"},{"location":"Domain-Model/#entities-and-value-objects","text":"Bond An entity characterized by ISIN and Universe . BondSpec A specification defining criteria like MaxMonthsToMature and MinAmountOutstanding for bonds. BondPrice An entity representing the price of a bond at a specific time, identified by ISIN , AsOf date, and ZSpread . BondPriceSpec A specification with criteria for bond prices, such as MinAsOf , MinZSpread , and MaxZSpread . BondWithPrices A value object representing a bond with its associated prices. BondWithPricesSpec A specification for BondWithPrices , including criteria like MaxEWMScore , MaxDODScore , etc. Universe An entity identified by Name , representing a collection of bonds. Bookmark An entity representing a bookmarked trade idea, identified by TradeIdeaID . BondPair A value object indicating a pair of bonds, possibly bookmarked. TradeIdeaCandidate An entity with attributes like ID , IsBookmarked , various spread values, and scores. TradeIdeaCandidateSpec A specification for trade idea candidates, including criteria like MinSpreadMeanReversion , MinPearsonScore , etc. Model An entity representing a predictive model, identified by ID . TradeIdeaSpec A specification for trade ideas, including criteria like MinSimilarityScore , MinPearsonScore , etc. TradeIdea An entity representing a potential trade idea, identified by a concatenated ID from two ISINs.","title":"Entities and Value Objects"},{"location":"Domain-Model/#relationships_2","text":"Bond -- BondWithPrices; BondPrice -- BondWithPrices: Bonds and their prices are associated with BondWithPrices . BondWithPrices o-- BondPair: Bond pairs are formed from bonds with prices. Bookmark ..> BondPair: Bookmarks can be associated with bond pairs. BondPair ..|> TradeIdeaCandidate; TradeIdeaCandidate ..|> TradeIdea: Bond pairs are used to generate trade idea candidates, which can become trade ideas. Specs to Entities/Value Objects: Specifications ( BondSpec , BondPriceSpec , etc.) are linked to their corresponding entities or value objects, defining criteria or rules for them. Universe o-- Bond; Universe o-- TradeIdea: Bonds and trade ideas are associated with universes. Model ..> TradeIdeaSpec; TradeIdeaSpec --> TradeIdeaCandidate: Models influence trade idea specifications, which in turn apply to trade idea candidates.","title":"Relationships"},{"location":"Domain-Model/#interpretation_1","text":"This model emphasizes the generation of trade ideas from bond data. It showcases how various specifications and criteria filter and refine bonds, their prices, and pairs to form viable trade idea candidates. The presence of value objects like BondWithPrices and BondPair indicates the aggregation of data from different entities to form meaningful combinations. The use of bookmarks suggests that certain bond pairs or trade ideas can be flagged for special attention. Finally, the transition from TradeIdeaCandidate to TradeIdea signifies the final step in the generation process, where candidates are evaluated against specific models and criteria to become actionable trade ideas.","title":"Interpretation"},{"location":"Domain-Model/#discover_1","text":"The Discover section of your domain model, illustrated using a mermaid class diagram, details the structure and interactions for discovering trade ideas within your financial system. This comprehensive model includes various entities, value objects, services, and their relationships. Let's delve into its components:","title":"Discover"},{"location":"Domain-Model/#entities-and-value-objects_1","text":"Bond An entity with attributes like ISIN , Name , IssueDate , IssuerName , CountryOfRisk , etc. BondPrice An entity representing a bond's price at a specific time, identified by ISIN , AsOf date, and ZSpread . BondPricePair A value object representing a pair of bond prices. BondPricePairWithStats A value object that includes statistics like Diff , Mean , StdDev , and an IsIdea flag. Universe An entity representing a collection of bonds, identified by Name . TradeIdea An entity representing a potential trade idea, identified by concatenated ISINs of BondBuy and BondSell . Filters (TagFilter, MatchFilter, LikeFilter, RangeFilter, ExcludeFilter) Value objects representing different types of filters used in search criteria. Page A value object for pagination details such as Number , Size , and Total . OrderDirection (Enum) and Order OrderDirection is an enumeration for sorting direction, and Order is a value object specifying the field and direction for ordering. SearchCriteria A value object defining the search criteria, including universe, filters, order, and pagination. Facets (TagFacet, RangeFacet, MatchFacet) Value objects representing facets for search results. SearchResult A value object encapsulating the results of a search, including items, facets, order, pagination, and total item count. TradeIdeaService (Service) A service for executing searches based on SearchCriteria and returning SearchResult .","title":"Entities and Value Objects"},{"location":"Domain-Model/#relationships_3","text":"BondPrice -- Bond; BondPricePair -- BondPrice: Bonds are associated with their prices, and bond price pairs are linked to individual bond prices. Bond -- Universe; TradeIdea -- Universe; SearchResult *-- Universe: Bonds, trade ideas, and search results are associated with universes. TradeIdea *-- Bond: Trade ideas are linked to buy and sell bonds. SearchCriteria o-- Filters; SearchResult o-- Facets: Search criteria include various filters, and search results contain facets. Order -- SearchCriteria; Page -- SearchCriteria; Order -- SearchResult; Page -- SearchResult: Order and page details are used in both search criteria and results. SearchCriteria ..> TradeIdeaService; TradeIdeaService ..|> SearchResult: Search criteria are used by the TradeIdeaService to generate search results.","title":"Relationships"},{"location":"Domain-Model/#interpretation_2","text":"This diagram illustrates the discovery process within the trading system, focusing on how trade ideas are identified, filtered, and presented. It highlights the importance of flexible search criteria, including various filters and sorting options, facilitating targeted searches within the bond universe. The presence of statistical value objects like BondPricePairWithStats suggests an analytical approach to identifying potential trade ideas. The TradeIdeaService plays a central role, acting as the interface for processing search queries and returning structured results. The model also emphasizes the importance of pagination and sorting in managing and presenting search results, ensuring a user-friendly discovery experience. Overall, the Discover section of your domain model portrays a robust system for exploring and identifying trade opportunities in the financial market.","title":"Interpretation"},{"location":"Domain-Model/#authenticate-collaborate","text":"The Authenticate & Collaborate section of your domain model illustrates the structure and interactions of entities and services involved in user authentication and collaboration in the context of a financial trading system. It includes entities like Team , AuthUser , User , bookmarks, comments, and channels, along with streams for bookmarks and comments. Let's break down the main components and their relationships:","title":"Authenticate &amp; Collaborate"},{"location":"Domain-Model/#entities-and-aggregates","text":"Team Represents a team within a company, with attributes like Company and Name . AuthUser Represents an authenticated user, identified by UID and Email . User Represents a user within the system, linked to a company, team, and authenticated user ID ( UID ). EnrichedUser An aggregate that enriches an AuthUser with more detailed information from User . Bookmark Represents a bookmarked trade idea, associated with a user, team, and specific trade idea ID. BookmarkChannel An entity that allows users to publish and subscribe to bookmarks. It is associated with a specific team. Comment Represents a user's comment, linked to a team and user. CommentChannel An entity for publishing and subscribing to comments, associated with a team.","title":"Entities and Aggregates"},{"location":"Domain-Model/#streams","text":"BookmarkStream and CommentStream Streams for bookmarks and comments, respectively, facilitating real-time communication and updates.","title":"Streams"},{"location":"Domain-Model/#relationships_4","text":"AuthUser -- EnrichedUser; User -- EnrichedUser: Authenticated users are enriched with additional information to form EnrichedUser . User, Bookmark, Comment --> Team: Users, bookmarks, and comments are associated with a specific team. Bookmark, Comment --> User: Bookmarks and comments are linked to individual users. Bookmark o-- BookmarkStream; Comment o-- CommentStream: Bookmarks and comments are part of their respective streams. BookmarkChannel, CommentChannel --> Team: Channels for bookmarks and comments are tied to specific teams. BookmarkChannel, CommentChannel ..|> BookmarkStream, CommentStream: Channels publish to and subscribe from their respective streams. User ..|> BookmarkChannel, CommentChannel: Users can publish to and subscribe from bookmark and comment channels.","title":"Relationships"},{"location":"Domain-Model/#interpretation_3","text":"The model emphasizes the collaborative aspect of the trading system, where users within a company's teams can interact, share insights, and collaborate on trade ideas. It highlights the importance of real-time communication through bookmark and comment channels, supported by streams that ensure continuous updates and interactions. The inclusion of AuthUser and EnrichedUser suggests a robust authentication system that securely manages user identities while enriching them with relevant team and company information. This ensures that users operate within the context of their organizational structures, maintaining data security and compliance. The model also demonstrates the use of bookmarks and comments as key collaborative tools, allowing users to highlight important trade ideas and engage in discussions. This fosters a community-driven approach to decision-making and idea generation in the financial trading environment. Overall, the Authenticate & Collaborate section of your domain model portrays a sophisticated and secure platform for user authentication and collaboration, enhancing the user experience in a financial trading system.","title":"Interpretation"},{"location":"Domain-Model/#notify","text":"The Notify section of your domain model outlines the notification system within your application, primarily focusing on how users receive notifications. Here's a breakdown of the components and their relationships:","title":"Notify"},{"location":"Domain-Model/#entities-and-value-objects_2","text":"User Represents a user in the system, uniquely identified by UID . Notification Represents a notification entity containing an ID , Text (message of the notification), and Link (possibly pointing to related content or action). NotificationChannel A value object that represents a channel through which users can subscribe to receive notifications.","title":"Entities and Value Objects"},{"location":"Domain-Model/#stream_1","text":"NotificationStream A stream that holds all the notifications, serving as a central pipeline through which notifications flow.","title":"Stream"},{"location":"Domain-Model/#relationships_5","text":"Notification o-- NotificationStream: Notifications are part of the NotificationStream, indicating that all notifications flow through this centralized stream. NotificationChannel ..> NotificationStream: The NotificationChannel subscribes to the NotificationStream. This relationship implies that the channel receives data from the stream, likely to forward it to subscribed users. User ..> NotificationChannel: Users subscribe to the NotificationChannel to receive notifications. This relationship indicates that notifications are pushed to users through these channels.","title":"Relationships"},{"location":"Domain-Model/#interpretation_4","text":"The model illustrates a straightforward notification system. When a notification is created, it enters the NotificationStream. NotificationChannels are subscribed to this stream, and they relay notifications to users who have subscribed to these channels. The use of a stream for notifications suggests a real-time or near-real-time system where notifications are continuously pushed through the stream and distributed to users. This approach is effective for applications requiring timely updates, such as messaging apps, social media platforms, or systems where prompt user response is critical. The simplicity of the model focuses on the flow of notifications from their creation to the end user. It abstracts away the complexities of how notifications are generated or the criteria for pushing specific notifications to particular users. This high-level view is beneficial for understanding the overall architecture without getting bogged down in implementation details. In summary, the Notify section of your domain model provides a clear picture of the notification delivery mechanism in your application, emphasizing real-time communication and user engagement.","title":"Interpretation"},{"location":"EWM-DOD-Definitions/","text":"Tolerance Metrics ewm_tolerance and dod_tolerance Parameters ewm_tolerance and dod_tolerance are used to control the sensitivity or tolerance levels of specific financial metrics when evaluating bonds and their prices over time. These parameters typically play a role in filtering bonds based on their historical performance, particularly in relation to price stability and volatility. Definitions ewm_tolerance (Expected Weighted Average Mean Tolerance): - **EWM** stands for **Exponentially Weighted Moving Average**. This is a statistical technique used to assign greater weight to more recent data points while discounting older data. - **ewm_tolerance** sets the threshold for how much variation or deviation is allowed in a bond's exponentially weighted average price movement. If the bond's price volatility (as measured by EWM) exceeds this tolerance level, the bond may be excluded from further consideration in the trade idea generation process. - **Purpose**: To ensure that bonds with stable, predictable price trends are considered for trade ideas. Bonds with excessive price swings or volatility are filtered out by setting a lower tolerance for price fluctuations. **Example**: If `ewm_tolerance` is set to 5.0, this means that the bond's price volatility, as calculated using the EWM method, must be within a 5% deviation to be included in the analysis. Bonds with volatility beyond this threshold would be excluded. dod_tolerance (Day Over Day Tolerance): - **DOD** stands for **Day Over Day** and refers to changes in a bond's price from one day to the next. - **dod_tolerance** defines the allowable threshold for day-over-day price changes. If the bond's day-over-day price fluctuations exceed the tolerance level, the bond might be considered too volatile and will be excluded from further analysis. - **Purpose**: This tolerance ensures that only bonds with relatively stable day-to-day price movements are considered. Large or erratic day-over-day price swings are generally seen as a sign of high risk, and bonds exceeding this tolerance are filtered out. **Example**: If `dod_tolerance` is set to 5.0, the bond's day-to-day price fluctuations must stay within 5% for the bond to be included in the analysis. Bonds with daily price changes beyond this threshold would be excluded from further consideration. Why Are These Tolerances Important? Both ewm_tolerance and dod_tolerance are designed to filter out bonds that exhibit too much price volatility. The goal is to focus on bonds with more stable price patterns, which are often preferred in trade ideas because they carry less risk. By setting thresholds for acceptable levels of volatility, the system can narrow down the pool of bonds to those that are more predictable and less likely to be affected by sudden price swings. Application in the Generate Process These tolerances are applied as part of the BondWithPricesSpec , which filters bonds with associated pricing data. If the bond's price volatility, as measured by the EWM and DOD scores, exceeds the defined tolerance levels, that bond is excluded from the trade idea generation process. Bonds that meet both the ewm_tolerance and dod_tolerance thresholds are considered more stable and are passed on for further evaluation as TradeIdeaCandidates . ```","title":"Tolerance Metrics ewm_tolerance and dod_tolerance"},{"location":"EWM-DOD-Definitions/#tolerance-metrics-ewm_tolerance-and-dod_tolerance","text":"Parameters ewm_tolerance and dod_tolerance are used to control the sensitivity or tolerance levels of specific financial metrics when evaluating bonds and their prices over time. These parameters typically play a role in filtering bonds based on their historical performance, particularly in relation to price stability and volatility.","title":"Tolerance Metrics ewm_tolerance and dod_tolerance"},{"location":"EWM-DOD-Definitions/#definitions","text":"ewm_tolerance (Expected Weighted Average Mean Tolerance): - **EWM** stands for **Exponentially Weighted Moving Average**. This is a statistical technique used to assign greater weight to more recent data points while discounting older data. - **ewm_tolerance** sets the threshold for how much variation or deviation is allowed in a bond's exponentially weighted average price movement. If the bond's price volatility (as measured by EWM) exceeds this tolerance level, the bond may be excluded from further consideration in the trade idea generation process. - **Purpose**: To ensure that bonds with stable, predictable price trends are considered for trade ideas. Bonds with excessive price swings or volatility are filtered out by setting a lower tolerance for price fluctuations. **Example**: If `ewm_tolerance` is set to 5.0, this means that the bond's price volatility, as calculated using the EWM method, must be within a 5% deviation to be included in the analysis. Bonds with volatility beyond this threshold would be excluded. dod_tolerance (Day Over Day Tolerance): - **DOD** stands for **Day Over Day** and refers to changes in a bond's price from one day to the next. - **dod_tolerance** defines the allowable threshold for day-over-day price changes. If the bond's day-over-day price fluctuations exceed the tolerance level, the bond might be considered too volatile and will be excluded from further analysis. - **Purpose**: This tolerance ensures that only bonds with relatively stable day-to-day price movements are considered. Large or erratic day-over-day price swings are generally seen as a sign of high risk, and bonds exceeding this tolerance are filtered out. **Example**: If `dod_tolerance` is set to 5.0, the bond's day-to-day price fluctuations must stay within 5% for the bond to be included in the analysis. Bonds with daily price changes beyond this threshold would be excluded from further consideration.","title":"Definitions"},{"location":"EWM-DOD-Definitions/#why-are-these-tolerances-important","text":"Both ewm_tolerance and dod_tolerance are designed to filter out bonds that exhibit too much price volatility. The goal is to focus on bonds with more stable price patterns, which are often preferred in trade ideas because they carry less risk. By setting thresholds for acceptable levels of volatility, the system can narrow down the pool of bonds to those that are more predictable and less likely to be affected by sudden price swings.","title":"Why Are These Tolerances Important?"},{"location":"EWM-DOD-Definitions/#application-in-the-generate-process","text":"These tolerances are applied as part of the BondWithPricesSpec , which filters bonds with associated pricing data. If the bond's price volatility, as measured by the EWM and DOD scores, exceeds the defined tolerance levels, that bond is excluded from the trade idea generation process. Bonds that meet both the ewm_tolerance and dod_tolerance thresholds are considered more stable and are passed on for further evaluation as TradeIdeaCandidates . ```","title":"Application in the Generate Process"},{"location":"Front-End/","text":"The Front End React Redux , Thunk redux/tookit Store Location of React Store https://gitlab.com/katanalabs/katana/-/blob/master/services/admin/frontend/src/store/store.js Reducers [Location of Reducers] (url)https://gitlab.com/katanalabs/katana/-/tree/master/services/admin/frontend/src/store/reducers","title":"The Front End"},{"location":"Front-End/#the-front-end","text":"React Redux , Thunk redux/tookit","title":"The Front End"},{"location":"Front-End/#store","text":"Location of React Store https://gitlab.com/katanalabs/katana/-/blob/master/services/admin/frontend/src/store/store.js","title":"Store"},{"location":"Front-End/#reducers","text":"[Location of Reducers] (url)https://gitlab.com/katanalabs/katana/-/tree/master/services/admin/frontend/src/store/reducers","title":"Reducers"},{"location":"Functions/","text":"","title":"Functions"},{"location":"GCP-Alternatives/","text":"GCP Current Workflow The model processes bond pairs and makes predictions using: Z-spread differences Historical pricing data Forward-filled missing values Normalized inputs If you're interested in seeing how the actual model works, I'd recommend looking at: pipelines/generate/models/compression_probability_model.py pipelines/generate/components/model_loaders/vertex_ai.py The system appears to use Google Cloud's Vertex AI for model serving rather than traditional time series models like ARIMA. Here's a breakdown of vertex_ai.py and how to implement it on other cloud providers: Current Implementation (Google Cloud): class VertexAIModelLoader: # Initializes connection to Google Cloud def init (self, project_id: str, location: str) # Loads model from Vertex AI endpoint def load(self, model_id: str, model_options: Dict[str, Any]) -> Model class VertexAIModelClient: # Makes predictions using loaded endpoint def predict(self, candidate: IdeaCandidate) -> ModelResult Core Components Required for Any Cloud Provider: Model endpoint management Authentication Prediction service Response handling Implementation Guide for Other Providers: AWS AWS Implementation: class SageMakerModelLoader(ModelLoader): def init (self, region: str): import boto3 self.sagemaker = boto3.client('sagemaker-runtime') def load(self, model_id: str, model_options: Dict[str, Any]) -> Model: return SageMakerModelClient( endpoint_name=model_id, sagemaker_client=self.sagemaker ) class SageMakerModelClient(Model): def predict(self, candidate: IdeaCandidate) -> ModelResult: response = self.sagemaker_client.invoke_endpoint( EndpointName=self.endpoint_name, Body=json.dumps(candidate.to_json()) ) prediction = json.loads(response['Body'].read()) return ModelResult(**prediction) Azure Implementation: class AzureMLModelLoader(ModelLoader): def init (self, workspace: str): from azureml.core import Workspace self.ws = Workspace.from_config(workspace) def load(self, model_id: str, model_options: Dict[str, Any]) -> Model: return AzureMLModelClient( endpoint_name=model_id, workspace=self.ws ) class AzureMLModelClient(Model): def predict(self, candidate: IdeaCandidate) -> ModelResult: service = Model.get_service(self.workspace, self.endpoint_name) response = service.run(json.dumps(candidate.to_json())) return ModelResult(**response) Key requirements for any implementation: Model serving endpoint Authentication mechanism JSON serialization/deserialization Error handling Response formatting to match ModelResult interface The core logic remains the same - only the cloud-specific SDK calls need to be adapted.","title":"GCP Current Workflow"},{"location":"GCP-Alternatives/#gcp-current-workflow","text":"The model processes bond pairs and makes predictions using: Z-spread differences Historical pricing data Forward-filled missing values Normalized inputs If you're interested in seeing how the actual model works, I'd recommend looking at: pipelines/generate/models/compression_probability_model.py pipelines/generate/components/model_loaders/vertex_ai.py The system appears to use Google Cloud's Vertex AI for model serving rather than traditional time series models like ARIMA. Here's a breakdown of vertex_ai.py and how to implement it on other cloud providers: Current Implementation (Google Cloud): class VertexAIModelLoader: # Initializes connection to Google Cloud def init (self, project_id: str, location: str) # Loads model from Vertex AI endpoint def load(self, model_id: str, model_options: Dict[str, Any]) -> Model class VertexAIModelClient: # Makes predictions using loaded endpoint def predict(self, candidate: IdeaCandidate) -> ModelResult","title":"GCP Current Workflow"},{"location":"GCP-Alternatives/#core-components-required-for-any-cloud-provider","text":"Model endpoint management Authentication Prediction service Response handling Implementation Guide for Other Providers:","title":"Core Components Required for Any Cloud Provider:"},{"location":"GCP-Alternatives/#aws","text":"AWS Implementation: class SageMakerModelLoader(ModelLoader): def init (self, region: str): import boto3 self.sagemaker = boto3.client('sagemaker-runtime') def load(self, model_id: str, model_options: Dict[str, Any]) -> Model: return SageMakerModelClient( endpoint_name=model_id, sagemaker_client=self.sagemaker ) class SageMakerModelClient(Model): def predict(self, candidate: IdeaCandidate) -> ModelResult: response = self.sagemaker_client.invoke_endpoint( EndpointName=self.endpoint_name, Body=json.dumps(candidate.to_json()) ) prediction = json.loads(response['Body'].read()) return ModelResult(**prediction)","title":"AWS"},{"location":"GCP-Alternatives/#azure-implementation","text":"class AzureMLModelLoader(ModelLoader): def init (self, workspace: str): from azureml.core import Workspace self.ws = Workspace.from_config(workspace) def load(self, model_id: str, model_options: Dict[str, Any]) -> Model: return AzureMLModelClient( endpoint_name=model_id, workspace=self.ws ) class AzureMLModelClient(Model): def predict(self, candidate: IdeaCandidate) -> ModelResult: service = Model.get_service(self.workspace, self.endpoint_name) response = service.run(json.dumps(candidate.to_json())) return ModelResult(**response) Key requirements for any implementation: Model serving endpoint Authentication mechanism JSON serialization/deserialization Error handling Response formatting to match ModelResult interface The core logic remains the same - only the cloud-specific SDK calls need to be adapted.","title":"Azure Implementation:"},{"location":"Generate/","text":"Generate Domain In the Generate Domain of the Katana Domain Model, the process focuses on transforming raw data about bonds and their prices into actionable Trade Ideas . This domain is all about filtering, refining, and structuring bond data to generate meaningful trade ideas for financial decision-making. Let's break down the key components, entities, and specifications involved, as well as their roles in this process. Key Entities and Specifications in the Generate Domain: Bond : - This entity represents a financial instrument (a bond) with key attributes like `ISIN`, `Universe`, and various metadata (e.g., `IssuerName`, `CountryOfRisk`, `RatingCategory`, etc.). - In the Generate Domain, bonds are the primary assets under consideration for trade ideas. BondPrice : - This entity captures the price of a bond at a particular moment in time. It includes attributes like the `ISIN` (identifying the bond), `AsOf` (time of the price record), and the `ZSpread` (a measure of bond risk compared to a risk-free bond). - The bond's price history plays a critical role in evaluating trade ideas since pricing data over time provides insights into the bond's risk and potential profitability. BondSpec (Specification for Bonds): - This is a specification that defines constraints or filters for bonds. - **Key attributes**: - `MaxMonthsToMature`: Specifies the maximum remaining time to maturity for a bond to be considered. - `MinAmountOutstanding`: Ensures the bond has a sufficient amount of outstanding debt to be included (as liquidity is crucial for tradability). - The **BondSpec** ensures that only bonds meeting these criteria are included in the generation of trade ideas. BondPriceSpec (Specification for Bond Prices): - This defines constraints on bond prices. - **Key attributes**: - `MinAsOf`: Ensures the price data is recent enough to be considered. - `MinZSpread` and `MaxZSpread`: These define acceptable risk levels for bonds (via the ZSpread). - **BondPriceSpec** ensures that only bonds with acceptable risk and up-to-date price data are included in the generation process. BondWithPrices (Value Object): - A value object representing a bond along with its associated price history. - This combination allows the system to analyze both the bond's static attributes (like `IssuerName` and `RatingCategory`) and its dynamic attributes (like price changes and `ZSpread`) over time. BondWithPricesSpec (Specification for Bonds with Price History): - This specification filters bonds and their associated price histories based on various metrics. - **Key attributes**: - `MaxEWMScore` and `MaxDODScore`: These scores represent risk and price volatility metrics, respectively. Bonds that exceed these thresholds are excluded. - `MinLatestAsOf`: Ensures that the price data is recent. - `MinNrConsecutivePrices`: Requires bonds to have a sufficient history of consecutive price records. - The **BondWithPricesSpec** ensures that only bonds with stable price histories and acceptable risk are considered. TradeIdeaCandidate (Entity): - This entity represents potential trade ideas that are yet to be finalized or confirmed. - **Key attributes**: - `ID`: Uniquely identifies the trade idea candidate. - `IsBookmarked`: A boolean indicating if this trade idea has been flagged for special attention. - Various metrics such as `SpreadLastValue`, `SpreadMean`, `SpreadZScore`, and `PearsonScore` are used to evaluate the viability of the trade idea based on bond price spreads and other financial indicators. TradeIdeaCandidateSpec (Specification for Trade Idea Candidates): - This specification defines the criteria for generating trade idea candidates. - **Key attributes**: - `BookmarksExempt`: A boolean that determines if bookmarks influence the trade idea generation process. - `MinSpreadMeanReversion` and `MinNrOverlappingPrices`: These attributes ensure the spread between bond prices shows a trend or reversion to the mean, and that there is sufficient overlap in pricing history between the two bonds in the trade idea. - `MinPearsonScore`: A threshold to ensure a minimum correlation between the bonds in the trade idea. - **TradeIdeaCandidateSpec** ensures that only trade ideas with sufficiently reliable financial characteristics are generated. TradeIdea (Entity): - This entity represents a final, actionable trade idea, created from one or more trade idea candidates that passed all the specified criteria. - **Key attributes**: - `ID`: A unique identifier for the trade idea, typically derived from the bonds involved. - The `BondBuy` and `BondSell` attributes specify which bonds are to be purchased and sold, respectively. - A **TradeIdea** is generated after all the filtering and analysis has been completed and is ready for evaluation by traders or algorithms. TradeIdeaSpec (Specification for Trade Ideas): - This is the final layer of specification that trade ideas must pass to be considered viable. - **Key attributes**: - `MinSimilarityScore`, `MinPearsonScore`, and `MinZScoreForIdea`: These metrics ensure that only trade ideas with strong financial indicators are selected. For example, the Pearson Score measures the correlation between bond price movements. - `NeedsToBeIdea`: A boolean indicating whether the candidate trade must be generated as a trade idea. - **TradeIdeaSpec** ensures that only the best trade ideas, based on strong financial metrics, are selected for action. Generate Process Flow: Filter Bonds : - Bonds are first filtered through the **BondSpec**. Only bonds that meet criteria such as maximum months to maturity and a minimum amount of outstanding debt are considered. Filter Bond Prices : - Once the bonds are selected, their price histories are filtered using the **BondPriceSpec**, ensuring that only bonds with recent and acceptable price data (such as ZSpread) move forward in the process. Analyze Bond and Price History : - The **BondWithPricesSpec** further narrows down bonds based on their price volatility (`EWMScore` and `DODScore`), ensuring that only bonds with stable price histories and minimal volatility are included. Generate Trade Idea Candidates : - Trade idea candidates are generated from pairs of bonds, where one bond is considered for buying and the other for selling. - The **TradeIdeaCandidateSpec** applies filters to ensure that the bond pairs have a reasonable spread relationship (`SpreadMeanReversion`), sufficient price overlap, and correlation (`PearsonScore`). Refine Trade Ideas : - After trade idea candidates are created, they are further refined based on **TradeIdeaSpec**, which looks for the strongest candidates by evaluating financial metrics such as similarity scores and Z-scores. Generate Final Trade Ideas : - Once all filters and specifications have been applied, final **TradeIdeas** are generated. These ideas represent actionable trading opportunities, where one bond is suggested for purchase and the other for sale. Interpretation of the Generate Domain: The Generate Domain focuses on turning raw bond and bond price data into well-analyzed, viable trade ideas. BondSpec and BondPriceSpec filter out bonds and price data that do not meet the necessary criteria, while BondWithPricesSpec ensures that only bonds with stable price histories are considered. TradeIdeaCandidateSpec analyzes bond pairs and their pricing relationships to generate trade idea candidates, and TradeIdeaSpec applies final filtering to produce actionable Trade Ideas . This process is highly systematic, leveraging a series of specifications to ensure that the resulting trade ideas are backed by strong financial metrics, minimizing risk, and maximizing potential for profitable trades.","title":"Generate Domain"},{"location":"Generate/#generate-domain","text":"In the Generate Domain of the Katana Domain Model, the process focuses on transforming raw data about bonds and their prices into actionable Trade Ideas . This domain is all about filtering, refining, and structuring bond data to generate meaningful trade ideas for financial decision-making. Let's break down the key components, entities, and specifications involved, as well as their roles in this process.","title":"Generate Domain"},{"location":"Generate/#key-entities-and-specifications-in-the-generate-domain","text":"Bond : - This entity represents a financial instrument (a bond) with key attributes like `ISIN`, `Universe`, and various metadata (e.g., `IssuerName`, `CountryOfRisk`, `RatingCategory`, etc.). - In the Generate Domain, bonds are the primary assets under consideration for trade ideas. BondPrice : - This entity captures the price of a bond at a particular moment in time. It includes attributes like the `ISIN` (identifying the bond), `AsOf` (time of the price record), and the `ZSpread` (a measure of bond risk compared to a risk-free bond). - The bond's price history plays a critical role in evaluating trade ideas since pricing data over time provides insights into the bond's risk and potential profitability. BondSpec (Specification for Bonds): - This is a specification that defines constraints or filters for bonds. - **Key attributes**: - `MaxMonthsToMature`: Specifies the maximum remaining time to maturity for a bond to be considered. - `MinAmountOutstanding`: Ensures the bond has a sufficient amount of outstanding debt to be included (as liquidity is crucial for tradability). - The **BondSpec** ensures that only bonds meeting these criteria are included in the generation of trade ideas. BondPriceSpec (Specification for Bond Prices): - This defines constraints on bond prices. - **Key attributes**: - `MinAsOf`: Ensures the price data is recent enough to be considered. - `MinZSpread` and `MaxZSpread`: These define acceptable risk levels for bonds (via the ZSpread). - **BondPriceSpec** ensures that only bonds with acceptable risk and up-to-date price data are included in the generation process. BondWithPrices (Value Object): - A value object representing a bond along with its associated price history. - This combination allows the system to analyze both the bond's static attributes (like `IssuerName` and `RatingCategory`) and its dynamic attributes (like price changes and `ZSpread`) over time. BondWithPricesSpec (Specification for Bonds with Price History): - This specification filters bonds and their associated price histories based on various metrics. - **Key attributes**: - `MaxEWMScore` and `MaxDODScore`: These scores represent risk and price volatility metrics, respectively. Bonds that exceed these thresholds are excluded. - `MinLatestAsOf`: Ensures that the price data is recent. - `MinNrConsecutivePrices`: Requires bonds to have a sufficient history of consecutive price records. - The **BondWithPricesSpec** ensures that only bonds with stable price histories and acceptable risk are considered. TradeIdeaCandidate (Entity): - This entity represents potential trade ideas that are yet to be finalized or confirmed. - **Key attributes**: - `ID`: Uniquely identifies the trade idea candidate. - `IsBookmarked`: A boolean indicating if this trade idea has been flagged for special attention. - Various metrics such as `SpreadLastValue`, `SpreadMean`, `SpreadZScore`, and `PearsonScore` are used to evaluate the viability of the trade idea based on bond price spreads and other financial indicators. TradeIdeaCandidateSpec (Specification for Trade Idea Candidates): - This specification defines the criteria for generating trade idea candidates. - **Key attributes**: - `BookmarksExempt`: A boolean that determines if bookmarks influence the trade idea generation process. - `MinSpreadMeanReversion` and `MinNrOverlappingPrices`: These attributes ensure the spread between bond prices shows a trend or reversion to the mean, and that there is sufficient overlap in pricing history between the two bonds in the trade idea. - `MinPearsonScore`: A threshold to ensure a minimum correlation between the bonds in the trade idea. - **TradeIdeaCandidateSpec** ensures that only trade ideas with sufficiently reliable financial characteristics are generated. TradeIdea (Entity): - This entity represents a final, actionable trade idea, created from one or more trade idea candidates that passed all the specified criteria. - **Key attributes**: - `ID`: A unique identifier for the trade idea, typically derived from the bonds involved. - The `BondBuy` and `BondSell` attributes specify which bonds are to be purchased and sold, respectively. - A **TradeIdea** is generated after all the filtering and analysis has been completed and is ready for evaluation by traders or algorithms. TradeIdeaSpec (Specification for Trade Ideas): - This is the final layer of specification that trade ideas must pass to be considered viable. - **Key attributes**: - `MinSimilarityScore`, `MinPearsonScore`, and `MinZScoreForIdea`: These metrics ensure that only trade ideas with strong financial indicators are selected. For example, the Pearson Score measures the correlation between bond price movements. - `NeedsToBeIdea`: A boolean indicating whether the candidate trade must be generated as a trade idea. - **TradeIdeaSpec** ensures that only the best trade ideas, based on strong financial metrics, are selected for action.","title":"Key Entities and Specifications in the Generate Domain:"},{"location":"Generate/#generate-process-flow","text":"Filter Bonds : - Bonds are first filtered through the **BondSpec**. Only bonds that meet criteria such as maximum months to maturity and a minimum amount of outstanding debt are considered. Filter Bond Prices : - Once the bonds are selected, their price histories are filtered using the **BondPriceSpec**, ensuring that only bonds with recent and acceptable price data (such as ZSpread) move forward in the process. Analyze Bond and Price History : - The **BondWithPricesSpec** further narrows down bonds based on their price volatility (`EWMScore` and `DODScore`), ensuring that only bonds with stable price histories and minimal volatility are included. Generate Trade Idea Candidates : - Trade idea candidates are generated from pairs of bonds, where one bond is considered for buying and the other for selling. - The **TradeIdeaCandidateSpec** applies filters to ensure that the bond pairs have a reasonable spread relationship (`SpreadMeanReversion`), sufficient price overlap, and correlation (`PearsonScore`). Refine Trade Ideas : - After trade idea candidates are created, they are further refined based on **TradeIdeaSpec**, which looks for the strongest candidates by evaluating financial metrics such as similarity scores and Z-scores. Generate Final Trade Ideas : - Once all filters and specifications have been applied, final **TradeIdeas** are generated. These ideas represent actionable trading opportunities, where one bond is suggested for purchase and the other for sale.","title":"Generate Process Flow:"},{"location":"Generate/#interpretation-of-the-generate-domain","text":"The Generate Domain focuses on turning raw bond and bond price data into well-analyzed, viable trade ideas. BondSpec and BondPriceSpec filter out bonds and price data that do not meet the necessary criteria, while BondWithPricesSpec ensures that only bonds with stable price histories are considered. TradeIdeaCandidateSpec analyzes bond pairs and their pricing relationships to generate trade idea candidates, and TradeIdeaSpec applies final filtering to produce actionable Trade Ideas . This process is highly systematic, leveraging a series of specifications to ensure that the resulting trade ideas are backed by strong financial metrics, minimizing risk, and maximizing potential for profitable trades.","title":"Interpretation of the Generate Domain:"},{"location":"Idea-Generation/","text":"Idea Candidate Creation idea.py This module defines classes related to investment ideas, including IdeaCandidate and Idea. It provides functionality for creating, manipulating, and converting idea objects, which are used in the context of bond trading and analysis. Classes IdeaCandidate Represents a candidate for an investment idea. This class encapsulates information about potential bond trades, including the bonds to buy and sell, and various metrics related to the trade. Attributes idea_id (str): Unique identifier for the idea candidate. bond_buy (BondWithPricingHistory): The bond to buy in this idea. bond_sell (BondWithPricingHistory): The bond to sell in this idea. bookmark (bool): Whether this idea candidate is bookmarked. curve_trade (bool): Whether this is a curve trade. spread_last_value (Optional[float]): The last value of the spread. spread_last_zscore (Optional[float]): The last z-score of the spread. spread_mean (Optional[float]): The mean of the spread. spread_mean_reversion (Optional[float]): The mean reversion of the spread. similarity_score (Optional[float]): The similarity score of the idea. pearson_score (Optional[float]): The Pearson correlation score. Idea Represents a fully formed investment idea. This class encapsulates all information related to an investment idea, including the bonds to buy and sell, various metrics, and flags indicating the idea's status. Attributes idea_id (str): Unique identifier for the idea. alert (bool): Whether this idea should trigger an alert. new (bool): Whether this is a new idea. bookmark (bool): Whether this idea is bookmarked. alternative (bool): Whether this is an alternative idea. curve_trade (bool): Whether this is a curve trade. shortening (bool): Whether this trade involves shortening. bond_buy (Bond): The bond to buy in this idea. bond_sell (Bond): The bond to sell in this idea. spread_last_value (Optional[float]): The last value of the spread. spread_last_zscore (Optional[float]): The last z-score of the spread. spread_mean (Optional[float]): The mean of the spread. spread_mean_reversion (Optional[float]): The mean reversion of the spread. spread_diff (Optional[float]): The difference in spreads. similarity_score (Optional[float]): The similarity score of the idea. pearson_score (Optional[float]): The Pearson correlation score. adf_score (Optional[float]): The ADF (Augmented Dickey-Fuller) test score. Methods from_candidate ```python @staticmethod def from_candidate( candidate: IdeaCandidate, zspread_to_use: str, alert: bool, new: bool, alternative: bool, run_id: str, run_date: datetime, universe: str, adf_score: Optional[float], similarity_score: Optional[float] = None, pearson_score: Optional[float] = None, ) -> Idea: ````","title":"Idea Candidate Creation"},{"location":"Idea-Generation/#idea-candidate-creation","text":"idea.py This module defines classes related to investment ideas, including IdeaCandidate and Idea. It provides functionality for creating, manipulating, and converting idea objects, which are used in the context of bond trading and analysis.","title":"Idea Candidate Creation"},{"location":"Idea-Generation/#classes","text":"","title":"Classes"},{"location":"Idea-Generation/#ideacandidate","text":"Represents a candidate for an investment idea. This class encapsulates information about potential bond trades, including the bonds to buy and sell, and various metrics related to the trade.","title":"IdeaCandidate"},{"location":"Idea-Generation/#attributes","text":"idea_id (str): Unique identifier for the idea candidate. bond_buy (BondWithPricingHistory): The bond to buy in this idea. bond_sell (BondWithPricingHistory): The bond to sell in this idea. bookmark (bool): Whether this idea candidate is bookmarked. curve_trade (bool): Whether this is a curve trade. spread_last_value (Optional[float]): The last value of the spread. spread_last_zscore (Optional[float]): The last z-score of the spread. spread_mean (Optional[float]): The mean of the spread. spread_mean_reversion (Optional[float]): The mean reversion of the spread. similarity_score (Optional[float]): The similarity score of the idea. pearson_score (Optional[float]): The Pearson correlation score.","title":"Attributes"},{"location":"Idea-Generation/#idea","text":"Represents a fully formed investment idea. This class encapsulates all information related to an investment idea, including the bonds to buy and sell, various metrics, and flags indicating the idea's status.","title":"Idea"},{"location":"Idea-Generation/#attributes_1","text":"idea_id (str): Unique identifier for the idea. alert (bool): Whether this idea should trigger an alert. new (bool): Whether this is a new idea. bookmark (bool): Whether this idea is bookmarked. alternative (bool): Whether this is an alternative idea. curve_trade (bool): Whether this is a curve trade. shortening (bool): Whether this trade involves shortening. bond_buy (Bond): The bond to buy in this idea. bond_sell (Bond): The bond to sell in this idea. spread_last_value (Optional[float]): The last value of the spread. spread_last_zscore (Optional[float]): The last z-score of the spread. spread_mean (Optional[float]): The mean of the spread. spread_mean_reversion (Optional[float]): The mean reversion of the spread. spread_diff (Optional[float]): The difference in spreads. similarity_score (Optional[float]): The similarity score of the idea. pearson_score (Optional[float]): The Pearson correlation score. adf_score (Optional[float]): The ADF (Augmented Dickey-Fuller) test score.","title":"Attributes"},{"location":"Idea-Generation/#methods","text":"","title":"Methods"},{"location":"Idea-Generation/#from_candidate","text":"```python @staticmethod def from_candidate( candidate: IdeaCandidate, zspread_to_use: str, alert: bool, new: bool, alternative: bool, run_id: str, run_date: datetime, universe: str, adf_score: Optional[float], similarity_score: Optional[float] = None, pearson_score: Optional[float] = None, ) -> Idea: ````","title":"from_candidate"},{"location":"Important-Definitions/","text":"Understanding Key Concepts** UNIVERSES UNIVERSES is a dictionary that defines different investment universes. Each universe is an instance of the Universe class with specific parameters: UNIVERSES = { 'EGR': Universe(...), 'EMD': Universe(...), 'IGEUR': Universe(...), 'IGUS': Universe(...), 'SSA': Universe(...), } Universe Parameters Each Universe instance is initialized with parameters that define its characteristics: name : A string identifier for the universe. currencies : A list of Currency enum values. countries : Either a Region enum value or a list of Country enum values. classifications : A list of ClassificationSuperType enum values. issue_types : A list of IssueSubType enum values. payment_categories : A list of PaymentCategorySuperType enum values or tuples of ( PaymentCategorySuperType , PaymentCategorySubType ). min_rating : A Rating enum value representing the minimum acceptable rating. model_options : A dictionary of parameters for the model associated with this universe. max_workers : An integer specifying the maximum number of parallel workers for processing this universe. Additional parameters may include: industry_sectors_level1_include tickers_include min_amount_outstanding flags preferred_series country_type industry_sectors_level4_exclude tickers_exclude Universe Descriptions EGR (European Government-Related) : Focuses on European government-related bonds in EUR. EMD (Emerging Market Debt) : Covers bonds from emerging market countries in EUR and USD. IGEUR (Investment Grade Europe) : Represents investment-grade corporate bonds in EUR and GBP. IGUS (Investment Grade US) : Covers US investment-grade corporate bonds in USD. SSA (Supranational, Sub-sovereign, and Agency) : Focuses on high-rated bonds from specific European countries and organizations. Source Code Location ~/src/generate/universe_definitions.py Code imports several classes and enums from custom modules: from components.domain.bond import (ClassificationSubType, ClassificationSuperType, CountryType, Currency, IssueSubType, PaymentCategorySubType, PaymentCategorySuperType, Rating, Series) from components.domain.country import Country, Region from components.domain.universe import Universe SOVEREIGN_TICKERS A list of ticker symbols for sovereign bonds: SOVEREIGN_TICKERS = [ 'DBR', 'BKO', 'OBL', 'BGB', 'FRTR', 'LGB', 'RAGB', 'NETHER', 'RFGB', 'BELG', EMD_countries A list of Country enum values representing Emerging Market Debt countries: EMD_countries = [ Country.CHN, # China Country.IDN, # Indonesia Country.IND, # India A list comprehension that creates a list of all countries not in EMD_countries . This ensures that IGUS_countries includes only countries that are not classified as Emerging Market Debt, effectively separating them into a distinct group: Country.RUS, # Russia Country.ZAF, # South Africa Country.MEX, # Mexico Country.TUR, # Turkey Country.ARG, # Argentina Country.PHL # Philippines ] IGUS_countries A list comprehension that creates a list of all countries not in EMD_countries : IGUS_countries = [c for c in Country if c not in EMD_countries]","title":"Understanding Key Concepts**"},{"location":"Important-Definitions/#understanding-key-concepts","text":"","title":"Understanding Key Concepts**"},{"location":"Important-Definitions/#universes","text":"UNIVERSES is a dictionary that defines different investment universes. Each universe is an instance of the Universe class with specific parameters: UNIVERSES = { 'EGR': Universe(...), 'EMD': Universe(...), 'IGEUR': Universe(...), 'IGUS': Universe(...), 'SSA': Universe(...), } Universe Parameters Each Universe instance is initialized with parameters that define its characteristics: name : A string identifier for the universe. currencies : A list of Currency enum values. countries : Either a Region enum value or a list of Country enum values. classifications : A list of ClassificationSuperType enum values. issue_types : A list of IssueSubType enum values. payment_categories : A list of PaymentCategorySuperType enum values or tuples of ( PaymentCategorySuperType , PaymentCategorySubType ). min_rating : A Rating enum value representing the minimum acceptable rating. model_options : A dictionary of parameters for the model associated with this universe. max_workers : An integer specifying the maximum number of parallel workers for processing this universe. Additional parameters may include: industry_sectors_level1_include tickers_include min_amount_outstanding flags preferred_series country_type industry_sectors_level4_exclude tickers_exclude Universe Descriptions EGR (European Government-Related) : Focuses on European government-related bonds in EUR. EMD (Emerging Market Debt) : Covers bonds from emerging market countries in EUR and USD. IGEUR (Investment Grade Europe) : Represents investment-grade corporate bonds in EUR and GBP. IGUS (Investment Grade US) : Covers US investment-grade corporate bonds in USD. SSA (Supranational, Sub-sovereign, and Agency) : Focuses on high-rated bonds from specific European countries and organizations. Source Code Location ~/src/generate/universe_definitions.py Code imports several classes and enums from custom modules: from components.domain.bond import (ClassificationSubType, ClassificationSuperType, CountryType, Currency, IssueSubType, PaymentCategorySubType, PaymentCategorySuperType, Rating, Series) from components.domain.country import Country, Region from components.domain.universe import Universe SOVEREIGN_TICKERS A list of ticker symbols for sovereign bonds: SOVEREIGN_TICKERS = [ 'DBR', 'BKO', 'OBL', 'BGB', 'FRTR', 'LGB', 'RAGB', 'NETHER', 'RFGB', 'BELG', EMD_countries A list of Country enum values representing Emerging Market Debt countries: EMD_countries = [ Country.CHN, # China Country.IDN, # Indonesia Country.IND, # India A list comprehension that creates a list of all countries not in EMD_countries . This ensures that IGUS_countries includes only countries that are not classified as Emerging Market Debt, effectively separating them into a distinct group: Country.RUS, # Russia Country.ZAF, # South Africa Country.MEX, # Mexico Country.TUR, # Turkey Country.ARG, # Argentina Country.PHL # Philippines ] IGUS_countries A list comprehension that creates a list of all countries not in EMD_countries : IGUS_countries = [c for c in Country if c not in EMD_countries]","title":"UNIVERSES"},{"location":"Questions/","text":"Research on Current Questions What does the following error mean: \"Error response from daemon: container 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b is not connected to the network kind\"? The error message you encountered, \"Error response from daemon: container 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b is not connected to the network kind,\" indicates that the Docker container with the specified ID ( 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b ) is not connected to a Docker network named kind . Explanation of the Error In Docker, networks are used to allow containers to communicate with each other. If you attempt to execute a Docker command that relies on the container being connected to a specific network (like kind in this case), and the container isn't connected to that network, Docker will return this error. Common Scenarios Leading to This Error Network Not Specified at Container Run Time : When you start a container, you can specify the network it should connect to using the --network flag. If the container was started without specifying the kind network, or it was specified incorrectly, it won't be connected to that network. Container Disconnected from the Network : A container may have been explicitly disconnected from the kind network using the docker network disconnect command. Incorrect Network or Typo : The network name kind might not exist, or there could be a typo in the network name. Docker would then fail to find a network to connect the container. Network Misconfiguration or Removal : The network named kind might have been removed or is not set up properly. How to Resolve This Issue To resolve this error, you can follow these steps: Check Existing Networks Verify if the kind network exists by listing all networks: bash docker network ls If kind is not in the list, you need to create it or identify the correct network name. Connect the Container to the Network If the kind network exists and you just need to connect the container to it, use: bash docker network connect kind 5765df44dd59 Replace 5765df44dd59 with your actual container ID. Start a Container with the Correct Network If you're starting a new container, make sure to specify the network using the --network flag: bash docker run --network kind <other_options> <image_name> Create the Network if It Doesn\u2019t Exist If the kind network does not exist, create it: bash docker network create kind Inspect the Container To see which networks a container is connected to, use: bash docker inspect --format='{{json .NetworkSettings.Networks}}' 5765df44dd59 This will provide detailed network settings for the specified container. By following these steps, you should be able to resolve the error and connect your Docker container to the correct network. If you have any additional details or specific configuration requirements, feel free to share!","title":"Research on Current Questions"},{"location":"Questions/#research-on-current-questions","text":"","title":"Research on Current Questions"},{"location":"Questions/#what-does-the-following-error-mean-error-response-from-daemon-container-5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b-is-not-connected-to-the-network-kind","text":"The error message you encountered, \"Error response from daemon: container 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b is not connected to the network kind,\" indicates that the Docker container with the specified ID ( 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b ) is not connected to a Docker network named kind .","title":"What does the following error mean: \"Error response from daemon: container 5765df44dd5998a92f7973a24b88606051b6eba9811993ed62e16948a81109b is not connected to the network kind\"?"},{"location":"Questions/#explanation-of-the-error","text":"In Docker, networks are used to allow containers to communicate with each other. If you attempt to execute a Docker command that relies on the container being connected to a specific network (like kind in this case), and the container isn't connected to that network, Docker will return this error.","title":"Explanation of the Error"},{"location":"Questions/#common-scenarios-leading-to-this-error","text":"Network Not Specified at Container Run Time : When you start a container, you can specify the network it should connect to using the --network flag. If the container was started without specifying the kind network, or it was specified incorrectly, it won't be connected to that network. Container Disconnected from the Network : A container may have been explicitly disconnected from the kind network using the docker network disconnect command. Incorrect Network or Typo : The network name kind might not exist, or there could be a typo in the network name. Docker would then fail to find a network to connect the container. Network Misconfiguration or Removal : The network named kind might have been removed or is not set up properly.","title":"Common Scenarios Leading to This Error"},{"location":"Questions/#how-to-resolve-this-issue","text":"To resolve this error, you can follow these steps: Check Existing Networks Verify if the kind network exists by listing all networks: bash docker network ls If kind is not in the list, you need to create it or identify the correct network name. Connect the Container to the Network If the kind network exists and you just need to connect the container to it, use: bash docker network connect kind 5765df44dd59 Replace 5765df44dd59 with your actual container ID. Start a Container with the Correct Network If you're starting a new container, make sure to specify the network using the --network flag: bash docker run --network kind <other_options> <image_name> Create the Network if It Doesn\u2019t Exist If the kind network does not exist, create it: bash docker network create kind Inspect the Container To see which networks a container is connected to, use: bash docker inspect --format='{{json .NetworkSettings.Networks}}' 5765df44dd59 This will provide detailed network settings for the specified container. By following these steps, you should be able to resolve the error and connect your Docker container to the correct network. If you have any additional details or specific configuration requirements, feel free to share!","title":"How to Resolve This Issue"},{"location":"model/","text":"Forecasting Models - How many exist? Prediction Model model.py This documentation provides an overview of the model.py module, including descriptions of the ModelResult , Model , and ModelLoader classes, their attributes, and methods. It's formatted in a way that's suitable for a GitLab wiki and can be easily integrated into your project documentation. This module defines abstract base classes for machine learning models and model loaders used in the project. Classes ModelResult Represents the result of a model prediction. Attributes alert (bool): Indicates whether an alert should be triggered. alternative (bool): Indicates whether this is an alternative result. similarity_score (Optional[float]): The similarity score of the prediction. pearson_score (Optional[float]): The Pearson correlation score. adf_score (Optional[float]): The Augmented Dickey-Fuller test score. Model An abstract base class for machine learning models. Attributes id (str): A unique identifier for the model. Methods _preprocess @abstractmethod def _preprocess(self, input: PI) -> PR: Model-specific transforms of the input data. Arguments: input (PI): The input data to preprocess. Returns: PR : The preprocessed data. predict @abstractmethod def predict(self, candidate: IdeaCandidate) -> ModelResult: Makes a prediction for a given candidate. Arguments: candidate (IdeaCandidate): The candidate to make a prediction for. Returns: ModelResult : The result of the prediction. save def save(self): Save the model (typically weights, e.g., for a neural network) to a path in GCloud. ModelLoader An abstract base class for model loaders. Methods load @abstractmethod def load(self, model_path: str, model_options: Optional[Dict[str, Any]]) -> Model: Loads a model from a specified path. Arguments: model_options (Optional[Dict[str, Any]]): Additional options for loading the model. Returns: Model : The loaded model. Type Variables PI : Type variable for model input. PR : Type variable for preprocessed input. Usage This module provides abstract base classes that should be inherited and implemented by concrete model and model loader classes. The Model class defines the interface for machine learning models used in the project, while the ModelLoader class defines how these models should be loaded. Example usage (implementation in a derived class): class ConcreteModel(Model[InputType, ProcessedType]): def _preprocess(self, input: InputType) -> ProcessedType: # Implement preprocessing logic pass def predict(self, candidate: IdeaCandidate) -> ModelResult: # Implement prediction logic pass class ConcreteModelLoader(ModelLoader): def load(self, model_path: str, model_options: Optional[Dict[str, Any]]) -> Model: # Implement model loading logic pass Note: The actual implementation of these classes will depend on the specific requirements of your project and the machine learning models you're using. What is the model id? Based on the parse_arguments function in the code, the model ID is specified as follows: parser.add_argument('--model_id', type=str, default='stationarity-model_a875ef6f-e259-4c42-8d49-aa8484bd4713') The default model ID is 'stationarity-model_a875ef6f-e259-4c42-8d49-aa8484bd4713' . This appears to be a unique identifier for the model, likely stored in Google Cloud Storage (GCS). The ID consists of two parts: 1. The model type: \"stationarity-model\" 2. A UUID: \"a875ef6f-e259-4c42-8d49-aa8484bd4713\" This model ID is used to locate and load the specific model for generating trade ideas. It's worth noting that this is the default value, and it could be overridden by providing a different model ID as a command-line argument when running the pipeline. Finding other models (possibly in experiments) To find other model IDs, you should look in the following places: Google Cloud Storage (GCS): Check the GCS bucket specified by the --models_bucket argument (default is 'models' ). Look for objects or folders with names following a similar pattern to the default model ID. Configuration Files: Search for YAML, JSON, or Python configuration files in your project that might list available models. Database: If your project uses a database to track models, query it for a list of model IDs. Model Registry: If you're using a model registry (like MLflow or Vertex AI Model Registry), check there for registered models. CI/CD Pipeline Configurations: Look in your CI/CD configurations (e.g., .gitlab-ci.yml , Jenkins files) for model ID references. Codebase: Search your codebase for files or functions that might define or use model IDs. Logs: Examine pipeline run logs to see which model IDs have been used in past executions. Team Communication: Ask your data science or machine learning team if they maintain a list of current model IDs. Model Training Scripts: Look for scripts that train models; they might generate and output model IDs. Since there's an abstract Model class defined, this class is designed to be generic and can be extended to create different types of models. The Model class in this file is abstract and defines a general structure for models, including methods for preprocessing, prediction, and saving. To find out if there are other models in your group or project that could replace the stationary model, you might want to: Check other Python files in your project for classes that inherit from this Model class. Look for implementations of the ModelLoader class, which might give clues about what models are available. Check the version control history to see if there have been recent additions or changes to model implementations. ```","title":"Forecasting Models - How many exist?"},{"location":"model/#forecasting-models-how-many-exist","text":"","title":"Forecasting Models - How many exist?"},{"location":"model/#prediction-model","text":"model.py This documentation provides an overview of the model.py module, including descriptions of the ModelResult , Model , and ModelLoader classes, their attributes, and methods. It's formatted in a way that's suitable for a GitLab wiki and can be easily integrated into your project documentation. This module defines abstract base classes for machine learning models and model loaders used in the project.","title":"Prediction Model"},{"location":"model/#classes","text":"","title":"Classes"},{"location":"model/#modelresult","text":"Represents the result of a model prediction.","title":"ModelResult"},{"location":"model/#attributes","text":"alert (bool): Indicates whether an alert should be triggered. alternative (bool): Indicates whether this is an alternative result. similarity_score (Optional[float]): The similarity score of the prediction. pearson_score (Optional[float]): The Pearson correlation score. adf_score (Optional[float]): The Augmented Dickey-Fuller test score.","title":"Attributes"},{"location":"model/#model","text":"An abstract base class for machine learning models.","title":"Model"},{"location":"model/#attributes_1","text":"id (str): A unique identifier for the model.","title":"Attributes"},{"location":"model/#methods","text":"","title":"Methods"},{"location":"model/#_preprocess","text":"@abstractmethod def _preprocess(self, input: PI) -> PR: Model-specific transforms of the input data. Arguments: input (PI): The input data to preprocess. Returns: PR : The preprocessed data.","title":"_preprocess"},{"location":"model/#predict","text":"@abstractmethod def predict(self, candidate: IdeaCandidate) -> ModelResult: Makes a prediction for a given candidate. Arguments: candidate (IdeaCandidate): The candidate to make a prediction for. Returns: ModelResult : The result of the prediction.","title":"predict"},{"location":"model/#save","text":"def save(self): Save the model (typically weights, e.g., for a neural network) to a path in GCloud.","title":"save"},{"location":"model/#modelloader","text":"An abstract base class for model loaders.","title":"ModelLoader"},{"location":"model/#methods_1","text":"","title":"Methods"},{"location":"model/#load","text":"@abstractmethod def load(self, model_path: str, model_options: Optional[Dict[str, Any]]) -> Model: Loads a model from a specified path. Arguments: model_options (Optional[Dict[str, Any]]): Additional options for loading the model. Returns: Model : The loaded model.","title":"load"},{"location":"model/#type-variables","text":"PI : Type variable for model input. PR : Type variable for preprocessed input.","title":"Type Variables"},{"location":"model/#usage","text":"This module provides abstract base classes that should be inherited and implemented by concrete model and model loader classes. The Model class defines the interface for machine learning models used in the project, while the ModelLoader class defines how these models should be loaded. Example usage (implementation in a derived class): class ConcreteModel(Model[InputType, ProcessedType]): def _preprocess(self, input: InputType) -> ProcessedType: # Implement preprocessing logic pass def predict(self, candidate: IdeaCandidate) -> ModelResult: # Implement prediction logic pass class ConcreteModelLoader(ModelLoader): def load(self, model_path: str, model_options: Optional[Dict[str, Any]]) -> Model: # Implement model loading logic pass Note: The actual implementation of these classes will depend on the specific requirements of your project and the machine learning models you're using.","title":"Usage"},{"location":"model/#what-is-the-model-id","text":"Based on the parse_arguments function in the code, the model ID is specified as follows: parser.add_argument('--model_id', type=str, default='stationarity-model_a875ef6f-e259-4c42-8d49-aa8484bd4713') The default model ID is 'stationarity-model_a875ef6f-e259-4c42-8d49-aa8484bd4713' . This appears to be a unique identifier for the model, likely stored in Google Cloud Storage (GCS). The ID consists of two parts: 1. The model type: \"stationarity-model\" 2. A UUID: \"a875ef6f-e259-4c42-8d49-aa8484bd4713\" This model ID is used to locate and load the specific model for generating trade ideas. It's worth noting that this is the default value, and it could be overridden by providing a different model ID as a command-line argument when running the pipeline.","title":"What is the model id?"},{"location":"model/#finding-other-models-possibly-in-experiments","text":"To find other model IDs, you should look in the following places: Google Cloud Storage (GCS): Check the GCS bucket specified by the --models_bucket argument (default is 'models' ). Look for objects or folders with names following a similar pattern to the default model ID. Configuration Files: Search for YAML, JSON, or Python configuration files in your project that might list available models. Database: If your project uses a database to track models, query it for a list of model IDs. Model Registry: If you're using a model registry (like MLflow or Vertex AI Model Registry), check there for registered models. CI/CD Pipeline Configurations: Look in your CI/CD configurations (e.g., .gitlab-ci.yml , Jenkins files) for model ID references. Codebase: Search your codebase for files or functions that might define or use model IDs. Logs: Examine pipeline run logs to see which model IDs have been used in past executions. Team Communication: Ask your data science or machine learning team if they maintain a list of current model IDs. Model Training Scripts: Look for scripts that train models; they might generate and output model IDs. Since there's an abstract Model class defined, this class is designed to be generic and can be extended to create different types of models. The Model class in this file is abstract and defines a general structure for models, including methods for preprocessing, prediction, and saving. To find out if there are other models in your group or project that could replace the stationary model, you might want to: Check other Python files in your project for classes that inherit from this Model class. Look for implementations of the ModelLoader class, which might give clues about what models are available. Check the version control history to see if there have been recent additions or changes to model implementations. ```","title":"Finding other models (possibly in experiments)"},{"location":"stationary-model/","text":"Stationarity Model stationarity_model Overview The stationarity_model.py file implements a stationarity model for analyzing and predicting investment ideas. It contains two main classes: StationarityModelLoader and StationarityModel. This model is designed to evaluate the stationarity of financial time series data and make predictions based on various similarity metrics. Classes StationarityModelLoader This class is responsible for loading the StationarityModel. Methods load def load(self, model_path: str, model_options: Optional[Dict[str, Any]] = None) -> Model Loads the StationarityModel from the given path. Parameters: model_path (str): The path to the model. model_options (Optional[Dict[str, Any]]): Additional options for the model. Returns: Model: An instance of StationarityModel. StationarityModel This class implements the stationarity model for analyzing investment ideas. Attributes adf_regression (str): Type of regression for ADF test (default: 'ct'). adf_threshold (float): Threshold for ADF test (default: 0.05). pearson_threshold (float): Threshold for Pearson correlation (default: 0.9). similarity_threshold (float): Threshold for similarity score (default: 0.7). zspread_to_use (str): Type of z-spread to use (default: 'zspread_mid_best'). min_zspread_to_alert (float): Minimum z-spread to trigger an alert (default: 5.0). min_zscore_to_alert (float): Minimum z-score to trigger an alert (default: 1.5). ### Methods init def init (self, id: str, options: Optional[Dict[str, Any]] = None) Initializes the StationarityModel with the given ID and options. _compute_cor_similarity def _compute_cor_similarity(self, cor1: Optional[Country], cor2: Optional[Country]) -> float Computes the similarity between two countries of risk. _compute_ig_similarity def _compute_ig_similarity(self, ig1: Optional[str], ig2: Optional[str]) -> float Computes the similarity between two industry groups. _compute_rating_similarity def _compute_rating_similarity(self, rating1: Optional[Rating], rating2: Optional[Rating]) -> float Computes the similarity between two ratings. _compute_maturity_similarity def _compute_maturity_similarity(self, maturity1: Optional[datetime], maturity2: Optional[datetime]) -> float Computes the similarity between two maturity dates. _compute_similarity def _compute_similarity(self, candidate: IdeaCandidate) -> Optional[float] Computes the overall similarity score for an idea candidate. _preprocess def _preprocess(self, candidate: IdeaCandidate) -> Tuple[str, str, pd.DataFrame] Preprocesses the data for the given candidate. This method is currently unused. predict def predict(self, candidate: IdeaCandidate, opts: Dict[str, Any] = None) -> ModelResult Makes a prediction for the given idea candidate. ### Parameters: candidate (IdeaCandidate): The idea candidate to evaluate. opts (Dict[str, Any]): Additional options for prediction (optional). Returns: ModelResult: The prediction result, including alert status, similarity score, and other metrics. Key Concepts Similarity Metrics: The model uses various similarity metrics (country of risk, industry group, rating, and maturity) to evaluate the relatedness of bonds in an idea candidate. Stationarity: While the class is named StationarityModel, the current implementation doesn't explicitly test for stationarity using methods like the Augmented Dickey-Fuller (ADF) test. The adf_score in the predict method is set to a constant value. Alert Generation: The model generates alerts based on similarity scores, bookmarks, curve trades, and z-score/z-spread thresholds. Usage The StationarityModel is typically used as part of a larger system for evaluating investment ideas. It's loaded using the StationarityModelLoader and then used to make predictions on IdeaCandidate objects. Example: loader = StationarityModelLoader() model = loader.load(\"path/to/model\") result = model.predict(idea_candidate) ``` Notes The current implementation sets constant values for Pearson correlation and ADF scores in the predict method. These might be placeholders for more sophisticated calculations in future versions. The _preprocess method is defined but unused in the current implementation. The model relies heavily on pre-computed similarity scores and thresholds. Adjusting these parameters may significantly affect the model's behavior. Stationary Model In Experiment Project model_utils/stationarity_model.py compute_zscore(df) function: Purpose: Computes the z-score of the present dislocation for a bond pair compared to its historic variances. Input: A DataFrame (df) with at least two columns. Process: a. Calculates the difference between the first and second columns of the input DataFrame. b. Computes the last value, mean (excluding the last value), and standard deviation of this difference. c. Calculates the average of the last 3 days' values. d. Computes the absolute difference between the 3-day average and the mean. e. Calculates the z-score by dividing the absolute difference by the standard deviation. Output: Returns the computed z-score. Note: Returns 0.0 if the standard deviation or the absolute difference is zero to avoid division by zero. compute_pearson_coefficients(df) function: Purpose: Calculates Pearson correlation coefficients between all columns in the input DataFrame. Input: A DataFrame (df) with multiple columns. Process: a. Computes the correlation matrix using df.corr(). b. Retains only the lower triangular part of the correlation matrix. c. Stacks the results into a Series. d. Resets the index and renames columns for clarity. Output: Returns a DataFrame with columns 'isin-1', 'isin-2', and 'pearson' (correlation coefficient). compute_pearson_scores(df_of_pairs, df) function: Purpose: Computes Pearson correlation scores for given pairs of items. Inputs: df_of_pairs: A DataFrame containing pairs to be correlated. df: The data DataFrame used to compute correlations. Process: a. Calls compute_pearson_coefficients(df) to get all pairwise correlations. b. Merges these correlations with the input pairs DataFrame. c. Cleans up the resulting DataFrame by handling potential duplicates and NaN values. Output: Returns a DataFrame with correlation scores for the input pairs. compute_adf_score(df, regression='ct', min_length=30) function: Purpose: Computes the Augmented Dickey-Fuller test statistic for stationarity. Inputs: df: A DataFrame with two columns representing two time series. regression: The type of regression to use in the ADF test (default 'ct' for constant and trend). min_length: Minimum length of the time series to perform the test (default 30). Process: a. Computes the difference between the two input time series. b. If the resulting series is long enough, performs the ADF test using statsmodels' adfuller function. c. Returns the p-value of the test. Output: Returns the ADF test p-value, or 1.0 if the series is too short, or NaN if there's an error. compute_return(df, predict_on_date, evaluate_on_date) function: Purpose: Computes the return between two dates for a pair of time series. Inputs: df: A DataFrame with two columns representing two time series. predict_on_date: The date to start the return calculation. evaluate_on_date: The date to end the return calculation. Process: a. Computes the difference between the two input time series. b. Calculates the return as the difference in this spread between the evaluation and prediction dates. c. Adjusts the sign of the return based on the position relative to the mean. Output: Returns the computed return.","title":"Stationarity Model"},{"location":"stationary-model/#stationarity-model","text":"stationarity_model Overview The stationarity_model.py file implements a stationarity model for analyzing and predicting investment ideas. It contains two main classes: StationarityModelLoader and StationarityModel. This model is designed to evaluate the stationarity of financial time series data and make predictions based on various similarity metrics.","title":"Stationarity Model"},{"location":"stationary-model/#classes","text":"","title":"Classes"},{"location":"stationary-model/#stationaritymodelloader","text":"This class is responsible for loading the StationarityModel. Methods load def load(self, model_path: str, model_options: Optional[Dict[str, Any]] = None) -> Model Loads the StationarityModel from the given path.","title":"StationarityModelLoader"},{"location":"stationary-model/#parameters","text":"model_path (str): The path to the model. model_options (Optional[Dict[str, Any]]): Additional options for the model. Returns: Model: An instance of StationarityModel. StationarityModel This class implements the stationarity model for analyzing investment ideas.","title":"Parameters:"},{"location":"stationary-model/#attributes","text":"adf_regression (str): Type of regression for ADF test (default: 'ct'). adf_threshold (float): Threshold for ADF test (default: 0.05). pearson_threshold (float): Threshold for Pearson correlation (default: 0.9). similarity_threshold (float): Threshold for similarity score (default: 0.7). zspread_to_use (str): Type of z-spread to use (default: 'zspread_mid_best'). min_zspread_to_alert (float): Minimum z-spread to trigger an alert (default: 5.0). min_zscore_to_alert (float): Minimum z-score to trigger an alert (default: 1.5). ### Methods init def init (self, id: str, options: Optional[Dict[str, Any]] = None) Initializes the StationarityModel with the given ID and options. _compute_cor_similarity def _compute_cor_similarity(self, cor1: Optional[Country], cor2: Optional[Country]) -> float Computes the similarity between two countries of risk. _compute_ig_similarity def _compute_ig_similarity(self, ig1: Optional[str], ig2: Optional[str]) -> float Computes the similarity between two industry groups. _compute_rating_similarity def _compute_rating_similarity(self, rating1: Optional[Rating], rating2: Optional[Rating]) -> float Computes the similarity between two ratings. _compute_maturity_similarity def _compute_maturity_similarity(self, maturity1: Optional[datetime], maturity2: Optional[datetime]) -> float Computes the similarity between two maturity dates. _compute_similarity def _compute_similarity(self, candidate: IdeaCandidate) -> Optional[float] Computes the overall similarity score for an idea candidate. _preprocess def _preprocess(self, candidate: IdeaCandidate) -> Tuple[str, str, pd.DataFrame] Preprocesses the data for the given candidate. This method is currently unused. predict def predict(self, candidate: IdeaCandidate, opts: Dict[str, Any] = None) -> ModelResult Makes a prediction for the given idea candidate. ### Parameters: candidate (IdeaCandidate): The idea candidate to evaluate. opts (Dict[str, Any]): Additional options for prediction (optional). Returns: ModelResult: The prediction result, including alert status, similarity score, and other metrics. Key Concepts Similarity Metrics: The model uses various similarity metrics (country of risk, industry group, rating, and maturity) to evaluate the relatedness of bonds in an idea candidate. Stationarity: While the class is named StationarityModel, the current implementation doesn't explicitly test for stationarity using methods like the Augmented Dickey-Fuller (ADF) test. The adf_score in the predict method is set to a constant value. Alert Generation: The model generates alerts based on similarity scores, bookmarks, curve trades, and z-score/z-spread thresholds. Usage The StationarityModel is typically used as part of a larger system for evaluating investment ideas. It's loaded using the StationarityModelLoader and then used to make predictions on IdeaCandidate objects. Example: loader = StationarityModelLoader() model = loader.load(\"path/to/model\") result = model.predict(idea_candidate) ```","title":"Attributes"},{"location":"stationary-model/#notes","text":"The current implementation sets constant values for Pearson correlation and ADF scores in the predict method. These might be placeholders for more sophisticated calculations in future versions. The _preprocess method is defined but unused in the current implementation. The model relies heavily on pre-computed similarity scores and thresholds. Adjusting these parameters may significantly affect the model's behavior.","title":"Notes"},{"location":"stationary-model/#stationary-model-in-experiment-project","text":"model_utils/stationarity_model.py compute_zscore(df) function: Purpose: Computes the z-score of the present dislocation for a bond pair compared to its historic variances. Input: A DataFrame (df) with at least two columns. Process: a. Calculates the difference between the first and second columns of the input DataFrame. b. Computes the last value, mean (excluding the last value), and standard deviation of this difference. c. Calculates the average of the last 3 days' values. d. Computes the absolute difference between the 3-day average and the mean. e. Calculates the z-score by dividing the absolute difference by the standard deviation. Output: Returns the computed z-score. Note: Returns 0.0 if the standard deviation or the absolute difference is zero to avoid division by zero. compute_pearson_coefficients(df) function: Purpose: Calculates Pearson correlation coefficients between all columns in the input DataFrame. Input: A DataFrame (df) with multiple columns. Process: a. Computes the correlation matrix using df.corr(). b. Retains only the lower triangular part of the correlation matrix. c. Stacks the results into a Series. d. Resets the index and renames columns for clarity. Output: Returns a DataFrame with columns 'isin-1', 'isin-2', and 'pearson' (correlation coefficient). compute_pearson_scores(df_of_pairs, df) function: Purpose: Computes Pearson correlation scores for given pairs of items. Inputs: df_of_pairs: A DataFrame containing pairs to be correlated. df: The data DataFrame used to compute correlations. Process: a. Calls compute_pearson_coefficients(df) to get all pairwise correlations. b. Merges these correlations with the input pairs DataFrame. c. Cleans up the resulting DataFrame by handling potential duplicates and NaN values. Output: Returns a DataFrame with correlation scores for the input pairs. compute_adf_score(df, regression='ct', min_length=30) function: Purpose: Computes the Augmented Dickey-Fuller test statistic for stationarity. Inputs: df: A DataFrame with two columns representing two time series. regression: The type of regression to use in the ADF test (default 'ct' for constant and trend). min_length: Minimum length of the time series to perform the test (default 30). Process: a. Computes the difference between the two input time series. b. If the resulting series is long enough, performs the ADF test using statsmodels' adfuller function. c. Returns the p-value of the test. Output: Returns the ADF test p-value, or 1.0 if the series is too short, or NaN if there's an error. compute_return(df, predict_on_date, evaluate_on_date) function: Purpose: Computes the return between two dates for a pair of time series. Inputs: df: A DataFrame with two columns representing two time series. predict_on_date: The date to start the return calculation. evaluate_on_date: The date to end the return calculation. Process: a. Computes the difference between the two input time series. b. Calculates the return as the difference in this spread between the evaluation and prediction dates. c. Adjusts the sign of the return based on the position relative to the mean. Output: Returns the computed return.","title":"Stationary Model In Experiment Project"}]}